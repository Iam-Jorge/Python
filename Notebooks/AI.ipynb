{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inteligencia artificial\n",
    "![title](../img/TitleDivider.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1. Introducción](#t1)\n",
    "    - [1.1. ¿Qué es la IA?](#t1_1)\n",
    "    - [1.2. Agentes inteligentes](#t1_2)\n",
    "- [2. Resolver problemas mediante búsqueda](#t2)\n",
    "    - [2.1. Estrategias de búsqueda no informada](#t2_1)\n",
    "    - [2.2. Estrategias de búsqueda informada y exploración](#t2_2)\n",
    "    - [2.3. Algoritmos de búsqueda local y problemas de optimización](#t2_3)\n",
    "- [3. Problemas de satisfacción de restricciones](#t3)\n",
    "    - [3.1. Problemas de satisfacción de restricciones](#t3_1)\n",
    "    - [3.2. Búsqueda con vuelta atráspara PSR](#t3_2)\n",
    "    - [3.3. Resolución por Búsqueda Local](#t3_3)\n",
    "- [4. Búsqueda entre adversarios.](#t4)\n",
    "    - [4.1. ](#t4_1)\n",
    "    - [4.2. ](#t4_2)\n",
    "    - [4.3. ](#t4_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción <a class=\"anchor\" id=\"t1\"></a>\n",
    "![title](../img/Divider.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante miles de años, hemos tratado de entender cómo pensamos; es decir, entender cómo un simple puñado de materia puede percibir, entender, predecir y manipular un mundo mucho más grande y complicado que ella misma. El campo de la inteligencia artificial,\n",
    "o IA, va más allá: no sólo intenta comprender, sino que también se esfuerza en construir entidades inteligentes.\n",
    "\n",
    "La IA es una de las ciencias más recientes. El trabajo comenzó poco después de la Segunda Guerra Mundial, y el nombre se acuñó en 1956.\n",
    "\n",
    "La IA abarca en la actualidad una gran variedad de subcampos, la IA **sintetiza y automatiza** tareas intelectuales y es, por lo tanto, potencialmente relevante para cualquier ámbito de la actividad intelectual humana. En este sentido, es un campo genuinamente universal.\n",
    "\n",
    "Una breve historia de las disciplinas que han contribuido con ideas, puntos de vista y técnicas al desarrollo en torno a una serie de cuestiones, con el objetivo último de todas estas disciplinas en hacer avanzar la IA.\n",
    "\n",
    "- Filosofía (desde el año 428 a.C. hasta el presente)\n",
    "- Matemáticas (aproximadamente desde el año 800 al presente)\n",
    "- Economía (desde el año 1776 hasta el presente)\n",
    "- Neurociencia (desde el año 1861 hasta el presente)\n",
    "- Psicología (desde el año 1879 hasta el presente)\n",
    "- Ingeniería computacional (desde el año 1940 hasta el presente)\n",
    "- Teoría de control y cibernética (desde el año 1948 hasta el presente)\n",
    "- Lingüística (desde el año 1957 hasta el presente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Historia (Breve) de la inteligencia artificial**\n",
    "\n",
    "- 1940-1950: Primeros días de la IA\n",
    "    - 1943: McCulloc & Pitts: Modelo Booleano del Cerebro.\n",
    "    - 1950: Turing: Computing Machinery and Intelligence.\n",
    "- 1950-1970: Mira Mamá, Sin Manos!!\n",
    "    - 1950s: Primeros programas de IA (Samuells, Newell,...)\n",
    "    - 1956: Adopción del término “Inteligencia Artificial”.\n",
    "    - 1965: Algoritmo de Robinson de Razonamiento Lógico.\n",
    "-  1970-1990: Sistemas Basados Conocimiento\n",
    "    - 1970s: Primeros sistemas basados en el Conocimiento.\n",
    "    - 1980s: Boom de los Sistemas Expertos.\n",
    "    - 1993: Pesimismo Sistemas Expertos: AI-Winter.\n",
    "- 1990-Hoy: Aproximaciones Modernas\n",
    "    - Probabilidad, Estadística e Incertidumbre.\n",
    "    - Incremento general en profundidad técnica.\n",
    "    - Agentes , Agentes , Agentes..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. ¿Qué es la IA? <a class=\"anchor\" id=\"t1_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lo largo de la historia se han seguido los cuatro enfoques representados en la siguiente figura:\n",
    "\n",
    "<center><img src=\"../img/AI-Figura1-1.jpeg\"/></center>\n",
    "\n",
    "Las que aparecen en la parte superior se refieren a **_procesos mentales y al razonamiento_**, mientras que los de la parte inferior aluden a la **_conducta_**.\n",
    "Las definiciones de la izquierda miden el éxito en términos de la fidelidad en la forma de actuar de los **_humanos_**, mientras que las de la derecha toman como referencia un concepto ideal de inteligencia, que llamaremos **_racionalidad_**.\n",
    "\n",
    "> Un sistema es racional si hace «lo correcto», en función de su conocimiento.\n",
    "\n",
    "- Piensan como Humanos (Ciencia cognitiva)\n",
    "- Piensan racionalmente (Leyes del pensamiento)\n",
    "- Actúan como humanos (Prueba de Turing)\n",
    "- Actúan Racionalmente (Agente Racional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comportamiento humano: el enfoque de la Prueba de Turing\n",
    "\n",
    "La Prueba de Turing, propuesta por Alan Turing (1950), se diseñó para proporcionar una definición operacional y satisfactoria de inteligencia. En vez de proporcionar una lista larga y quizá controvertida de cualidades necesarias para obtener inteligencia artificialmente, él sugirió una prueba basada en la incapacidad de diferenciar entre entidades inteligentes indiscutibles y seres humanos.\n",
    "\n",
    "El computador supera la prueba si un evaluador (humano) no es capaz de distinguir si las respuestas, a una serie de preguntas planteadas, son de una persona o no.\n",
    "\n",
    "Para superar la prueba de Turing el computador debería poseer las siguientes capacidades:\n",
    "- Procesamiento de lenguaje natural que le permita comunicarse satisfactoriamente en inglés.\n",
    "- Representación del conocimiento para almacenar lo que se conoce o siente.\n",
    "- Razonamiento automático para utilizar la información almacenada para responder a preguntas y extraer nuevas conclusiones.\n",
    "- Aprendizaje automático para adaptarse a nuevas circunstancias y para detectar y extrapolar patrones.\n",
    "\n",
    "El test global añade:\n",
    "- Visión computacional para percibir objetos.\n",
    "- Robótica para manipular y mover objetos.\n",
    "\n",
    "Estas seis disciplinas abarcan la mayor parte de la IA, y Turing merece ser reconocido por diseñar una prueba que se conserva vigente después de 50 años."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pensar como un humano: el enfoque del modelo cognitivo\n",
    "\n",
    "Para poder decir que un programa dado piensa como un humano, es necesario contar con un mecanismo para determinar cómo piensan los humanos. Es necesario penetrar en el funcionamiento de las mentes humanas. Hay dos formas de hacerlo:\n",
    "- Mediante introspección (intentando atrapar nuestros propios pensamientos conforme éstos van apareciendo).\n",
    "- Mediante experimentos psicológicos.\n",
    "\n",
    "Una vez se cuente con una teoría lo suficientemente precisa sobre cómo trabaja la mente, se podrá expresar esa teoría en la forma de un programa de computador.\n",
    "\n",
    "Si los datos de entrada/salida del programa y los tiempos de reacción son similares a los de un humano, existe la evidencia de que algunos de los mecanismos del programa se pueden comparar con los que utilizan los seres humanos. No basta con que el programa resielva correctamente los problemas, lo que interesa es seguir la pista de las etapas del proceso de razonamiento y compararlas con las seguidas por humanos a los que se les enfrentó a los mismos problemas. En el campo de la **_ciencia cognitiva_** convergen modelos computacionales de IA y técnicas experimentales de psicología intentando elaborar teorías precisas y verificables sobre el funcionamiento de la mente humana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pensamiento racional: el enfoque de las «leyes del pensamiento»\n",
    "\n",
    "El filósofo griego Aristóteles fue uno de los primeros en intentar codificar la «manera correcta de pensar», es decir, un proceso de razonamiento irrefutable. Sus silogismos son esquemas de estructuras de argumentación mediante las que siempre se llega a conclusiones correctas si se parte de premisas correctas. (por ejemplo: «Sócrates es un hombre; todos los hombres son mortales; por lo tanto Sócrates es mortal»). Estas leyes de pensamiento supuestamente gobiernan la manera de operar de la mente; su estudio fue el\n",
    "inicio de un campo llamado **_lógica_**.\n",
    "\n",
    "En el siglo XIX, se desarrollo una notación precisa para definir sentencias sobre todo tipo de elementos del mundo y especificar relaciones entre ellos (compárese esto con la notación aritmética). Ya en 1965 existían programas que, en principio, resolvían cualquier problema resoluble descrito en notación lógica. La llamada tradición logista dentro del campo de la inteligencia artificial trata de construir sistemas inteligentes a partir de estos programas. Este enfoque presenta dos obstáculos:\n",
    "- No es fácil transformar conocimiento informal y expresarlo en los términos formales que requieren de notación lógica.\n",
    "- Hay una gran diferencia entre poder resolver un problema «en principio» y hacerlo en la práctica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entonces qué es la IA?\n",
    "\n",
    "Es importante darse cuenta de que **la inteligencia no es una dimensión única** como la temperatura. Se puede comparar la temperatura de hoy con la de ayer, o la de Helsinki con la de Roma, y decir cuál es más alta y cuál más baja. Incluso tendemos a pensar que es posible clasificar a las personas en función de su inteligencia. Sin embargo, en el contexto de la IA, es obvio que los distintos sistemas de IA no pueden compararse en un único eje o dimensión en términos de su inteligencia. ¿Es más inteligente un algoritmo de ajedrez que un filtro de spam, o un sistema de recomendación musical que un coche autoconducido? Estas preguntas no tienen sentido. Esto se debe a que la inteligencia artificial es estrecha, ser capaz de resolver un problema no nos dice nada sobre la capacidad de resolver otro problema diferente.\n",
    "\n",
    "**¿Cuánto importa la filosofía en la práctica?**\n",
    "La definición de inteligencia, natural o artificial, y de conciencia parece ser extremadamente evasiva y da lugar a un discurso aparentemente interminable. Sin embargo, como señaló John McCarthy, _\"es poco probable que la filosofía de la IA tenga más efecto sobre la práctica de la investigación en IA que el que la filosofía de la ciencia tiene generalmente sobre la práctica de la ciencia\"_. Así pues, seguiremos investigando sistemas que sean útiles para resolver problemas prácticos sin preguntarnos demasiado si son inteligentes o sólo se comportan como si lo fueran."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conceptos clave**\n",
    "\n",
    "Declaración de John McCarthy sobre la IA _\"El estudio debe partir de la conjetura de que cada aspecto del aprendizaje o cualquier otra característica de la inteligencia puede, en principio, describirse con tanta precisión que se puede hacer que una máquina lo simule\"._\n",
    "\n",
    "En otras palabras, cualquier elemento de la inteligencia puede descomponerse en pequeños pasos, de modo que cada uno de ellos es tan simple y \"mecánico\" que puede escribirse como un programa informático. Esta afirmación era, y sigue siendo hoy, una conjetura, lo que significa que no podemos demostrar realmente que sea cierta.\n",
    "\n",
    "- Autonomía: Capacidad de realizar tareas en entornos complejos sin la guía constante de un usuario.\n",
    "- Adaptabilidad: Capacidad de mejorar el rendimiento aprendiendo de la experiencia.\n",
    "\n",
    "_IA general frente a IA restringida_\n",
    "\n",
    "La IA IA general frente a IA restringida se refiere a la IA que se ocupa de una sola tarea. La IA general o Inteligencia Artificial General (IAG) se refiere a una máquina que puede realizar cualquier tarea intelectual. Todos los métodos de IA que utilizamos hoy en día pertenecen a la IA restringida, mientras que la IA general se sitúa en el ámbito de la ciencia ficción. De hecho, el ideal de la IAG ha sido prácticamente abandonado por los investigadores de IA debido a la falta de progreso hacia ella en más de 50 años a pesar de todos los esfuerzos. En cambio, la IA IA general frente a IA restringida avanza a pasos agigantados.\n",
    "\n",
    "_IA fuerte frente a IA débil_\n",
    "\n",
    "Una dicotomía relacionada es la de IA \"fuerte\" y \"débil\". Esto se reduce a la distinción filosófica anterior entre ser inteligente y actuar de forma inteligente, subrayada por Searle. Una IA fuerte equivaldría a una \"mente\" realmente inteligente y consciente de sí misma. La IA débil es lo que realmente tenemos, es decir, sistemas que muestran comportamientos inteligentes a pesar de ser \"meros\" ordenadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Agentes inteligentes <a class=\"anchor\" id=\"t1_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un **agente** es cualquier entidad autónoma (software, hardware o ambas) capaz de percibir su entorno con la ayuda de **sensores** y actuar en ese entorno utilizando **actuadores**. El termino **percepción** se utiliza en este contexto para indicar que el agente puede recibir entradas en cualquier instante. La **secuencia de percepciones** de un agente refleja el historial completo de lo que el agente ha recibido.\n",
    "\n",
    "Un **agente racional**:\n",
    "- Hace lo correcto para obtener el mejor resultado.\n",
    "- Necesita definir una medida de rendimiento para obtener el mejor resultado.\n",
    "- Una medida de rendimiento evalua la secuencia de entorno.\n",
    "\n",
    "<center><img src=\"../img/AgenteIA.jpeg\"/></center>\n",
    "\n",
    "\n",
    "La función que describe el comportamiento de un agente se puede presentar en forma de tabla. Suponer un mundo hecho a medida para una aspiradora, que tiene solamente dos localizaciones: cuadrícula A y cuadrícula B. La aspiradora puede:\n",
    "- Percibir en qué cuadrante se encuentra.\n",
    "- Percibir si hay suciedad en el cuadrante. \n",
    "- Puede elegir si se mueve a la derecha, izquierda, aspirar la suciedad o no hacer nada.  \n",
    "\n",
    "Una función muy simple vendría dada por: si la cuadrícula en la que se encuentra está sucia, entonces aspirar, de otra forma, cambiar de cuadrícula.\n",
    "\n",
    "<center><img src=\"../img/AgenteAspirador.jpeg\"/></center>\n",
    "\n",
    "**Propiedades de un agente**\n",
    "- **Autonomía**: Es independiente, se apoya en el entorno.\n",
    "- **Sociabilidad**: Se comunica con otros iguales.\n",
    "- **Reactividad** Reacciona ante eventos.\n",
    "- **Proactividad**: Es capaz de promover acciones. \n",
    "- **Adaptabilidad**: Se pueden desenvolver ante cambios en el entorno sin cambiar el agente. \n",
    "- **Movilidad**: Es capaz de realizar acciones.\n",
    "- **Veracidad**: Si un agente tiene que hacer una acción realizara solo esa acción.\n",
    "- **Racionalidad**: Actúa racionalmente para que lo haga lo mejor posible de acuerdo a unos criterios. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Buen comportamiento: el concepto de racionalidad**\n",
    "\n",
    "“Actuar racionalmente consiste en realizar el conjunto de acciones que lleven a cumplir un objetivo de la mejor manera con el conocimiento que se tiene”. Por tanto, el comportamiento racional no requiere necesariamente de pensamiento (deliberación), y es totalmente independiente de las metas.\n",
    "\n",
    "La Racionalidad implica:\n",
    "- Exploración para recopilar información.\n",
    "- Aprendizaje de lo que percibe.\n",
    "- Autonomia para completar conocimiento parcial.\n",
    "\n",
    "**_Racionalidad_**\n",
    "\n",
    "En el caso del enfoque de la IA según las «leyes del pensamiento», todo el énfasis se pone en hacer inferencias correctas. Una manera racional de actuar es llegar a la conclusión lógica de que si una acción dada permite alcanzar un objetivo. Sin embargo, el efectuar una inferencia correcta no depende siempre de la racionalidad, ya que existen situaciones para las que no hay nada correcto que hacer y en las que hay que tomar una decisión.\n",
    "\n",
    "¿Qué significa hacer lo correcto? Como primera aproximación se puede decir que lo correcto es aquello que permite al agente obtener el mejor resultado posible.\n",
    "\n",
    "La racionalidad en un instante dado depende de cuatro factores:\n",
    "- La medida de rendimiento que define el criterio de exito.\n",
    "- El conocimiento del medio que tiene el agente.\n",
    "- Las acciones que el agente puede realizar.\n",
    "- La secuencia de percepciones recibida.\n",
    "\n",
    "Obtener una racionalidad perfecta (hacer siempre lo correcto) no es posible en entornos complejos. La demanda computacional que esto implica es demasiado grande. Se adoptará la hipótesis de trabajo de que la racionalidad perfecta es un buen punto de partida para el análisis. Lo cual simplifica el problema y proporciona el escenario base adecuado. Cuando no se cuenta con el tiempo suficiente para efectuar todos los cálculos deseables **_la racionalidad limitada_** nos permite actuar adecuadamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Entorno de trabajo_**\n",
    "\n",
    "Para diseñar un agente Racional el primer paso debe ser siempre especificar un Entorno de Trabajo de la forma más completa posible: REAS (Rendimiento, Entorno, Actuadores, Sensores).\n",
    "\n",
    "- **Rendimiento**. Cualidades deseables que el agente debería tener. Seguro, rápido, legal, viaje confortable, maximiza el beneficio.\n",
    "- **Entorno**. ¿Dónde se va a desenvolver nuestro agente? Carreteras, tráfico, peatones, clientes, tiempo (clima).\n",
    "- **Actuadores**. Elementos que nos permitan modificar ese entorno. Dirección, acelerador, freno, señal, bocina, visualizador...\n",
    "- **Sensores**. Permiten conocer la situación instantánea del entorno. Cámaras, sónar, GPS, tacómetro, acelerómetro, sensores del motor. \n",
    "\n",
    "**Propiedades de los entornos de trabajo**\n",
    "- **Totalmente observable vs. parcialmente observable**: Un entorno de trabajo es, efectivamente, totalmente observable si los sensores detectan todos los aspectos que son relevantes en la toma de decisiones.\n",
    "- **Determinista vs. estocástico**: Si el siguiente estado del medio está totalmente determinado por el estado actual y la acción ejecutada por el agente, entonces se dice que el entorno es determinista.\n",
    "- **Episódico vs. secuencial**: En un entorno de trabajo episódico, la experiencia del agente se divide en episodios atómicos, cada episodio consiste en la percepción del agente y la realización de una única acción posterior, donde cada elección de la acción en cada episodio depende sólo del episodio en sí mismo. En entornos secuenciales, por otro lado, la decisión presente puede afectar a decisiones futuras.\n",
    "- **Estático vs. dinámico**: En los nedios estáticos el agnete no necesita estar pendiente del mundo mientras está tomando una decisión, ni necesita preocuparse sobre el paso del tiempo. Los medios dinámicos, por el contrario, están preguntando continuamente al agente qué quiere hacer. Si el entorno no cambia con el paso del tiempo, pero el rendimiento del agente cambia, entonces se dice que el medio es semidinámico.\n",
    "- **Discreto vs. continuo**: La distinción entre discreto y continuo se puede aplicar al estado del medio, a la forma en la que se maneja el tiempo y a las percepciones y acciones del agente.\n",
    "- **Agente individual vs. multiagente**: La distinción entre el entorno de un agente individual y el de un sistema multiagente puede parecer suficientemente simple. Por ejemplo, un agente resolviendo un crucigrama por sí mismo está claramente en un entorno de agente individual, mientras que un agente que juega al ajedrez está en un entorno con dos agentes.\n",
    "\n",
    "La siguiente ficura presenta las propiedades de un número de entornos:\n",
    "\n",
    "<center><img src=\"../img/EntornosDeTrabajo.jpeg\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tipos de agentes**\n",
    "\n",
    "_¿Cómo trabaja internamente un agente?_\n",
    "\n",
    "El trabajo de la IA es diseñar el **programa del agente** que implemente la función del agente que proyecta las percepciones en las acciones. Se asume que este programa se ejecutará en algún tipo de computador con sensores físicos y actuadores, lo cual se conoce como **arquitectura**: \n",
    "\n",
    "**_Agente = arquitectura + programa_**\n",
    "\n",
    "Los programas de los agentes reciben las percepciones actuales como entradas de los sensores y devuelven una acción a los actuadores. Hay que tener en cuenta la diferencia entre los programas de los agentes, que toman la percepción actual como entrada, y la función del agente, que recibe la percepción histórica completa.\n",
    "\n",
    "Tipos básicos de programas para agentes que encarnan los principios que subyacen en casi todos los sistemas inteligentes:\n",
    "\n",
    "**_- Agentes reactivos simples._**\n",
    "El tipo de agente más sencillo es el agente reactivo simple. Estos agentes seleccionan las acciones sobre la base de las percepciones actuales, ignorando el resto de las percepciones históricas. \n",
    "\n",
    "**_- Agentes reactivos basados en modelos._**\n",
    "Un agente reactivo simple con estado interno, muestra cómo la percepción actual se combina con el estado interno antiguo para generar la descripción actualizada del estado actual. Además de interpretar la nueva percepción a partir del conocimiento existente sobre el estado, utiliza información relativa a la forma en la que evoluciona el mundo.\n",
    "La actualización del estado según pasa el tiempo requiere codificar dos tipos de conocimiento en el programa del agente.\n",
    "- Primero, se necesita alguna información acerca de cómo evoluciona el mundo independientemente del agente.\n",
    "- Segundo, se necesita más información sobre cómo afectan al mundo las acciones del agente.\n",
    "\n",
    "**_- Agentes basados en objetivos._** \n",
    "Es unn agente basado en objetivos y basado en modelos, que almacena información del estado del mundo, así como del conjunto de objetivos que intenta alcanzar, y que es capaz de seleccionar la acción que eventualmente lo guiará hacia la consecución de sus objetivos.\n",
    "\n",
    "**_- Agentes basados en utilidad._** \n",
    "Es un agente basado en utilidad y basado en modelos utiliza un modelo del mundo, junto con una función de utilidad que calcula sus preferencias entre los estados del mundo.\n",
    "- Primero, cuando haya objetivos conflictivos, y sólo se puedan alcanzar algunos de ellos.\n",
    "- Segundo, cuando haya varios objetivos por los que se pueda guiar el agente, y ninguno de ellos se pueda alcanzar con certeza.\n",
    "\n",
    "**_- Agentes que aprenden._** \n",
    "Un agente que aprende se puede dividir en cuatro componentes conceptuales. La distinción más entre el **elemento de aprendizaje** y el **elemento de actuación** es que el primero está responsabilizado de hacer mejoras y el segundo se responsabiliza de la selección de acciones externas. \n",
    "\n",
    "El elemento de aprendizaje se realimenta con las críticas sobre la actuación del agente y determina cómo se debe modificar el elemento de actuación para proporcionar mejores resultados en el futuro.\n",
    "\n",
    "La crítica indica al elemento de aprendizaje qué tal lo está haciendo el agente con respecto a un nivel de actuación fijo,  la percepción por sí misma no lo indica.\n",
    "\n",
    "El generador de problemas es responsable de sugerir acciones que lo guiarán hacia experiencias nuevas e informativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Resolver problemas mediante búsqueda<a class=\"anchor\" id=\"t2\"></a>\n",
    "![title](../img/Divider.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muchos problemas pueden plantearse como problemas de búsqueda. Para ello hay que empezar por formular las opciones alternativas y sus consecuencias.\n",
    "\n",
    "La búsqueda en práctica consiste en llegar de un punto A a otro punto B. Esta cuestión pertenece a la clase de los problemas de búsqueda y planificación. Problemas similares tienen que resolver los coches que se conducen solos y (quizá de forma menos obvia) la IA para jugar a juegos. En el ajedrez, por ejemplo, la dificultad no estriba tanto en llevar una pieza de A a B como en mantener las piezas a salvo del adversario.\n",
    "\n",
    "\n",
    "A menudo hay muchas formas diferentes de resolver el problema, algunas de las cuales pueden ser más preferibles en términos de tiempo, esfuerzo, coste u otros criterios. Las distintas técnicas de búsqueda pueden conducir a soluciones diferentes, y el desarrollo de algoritmos de búsqueda avanzados es un área de investigación consolidada.\n",
    "\n",
    "**Etapas del proceso de resolución de problemas:**\n",
    "- Definición de las opciones y sus consecuencias.\n",
    "- Definir cuál es nuestro objetivo.\n",
    "- Buscar una secuencia de acciones que nos lleve del estado inicial al objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se describe una clase de **agente basado en objetivos** llamado agente **resolvente-problemas**, que deciden qué hacer para encontrar secuencias de acciones que conduzcan a los estados deseables. Se describe con precisión los elementos que constituyen el **problema** y su **solución**. Posteriormente, se describen los algoritmos de propósito general que podamos utilizar para resolver estos problemas y así comparar las ventajas de cada algoritmo. \n",
    "\n",
    "Los problemas de búsqueda implican un agente al que se le da un _estado inicial_ y un _estado objetivo_, y que devuelve una solución de cómo llegar del primero al segundo. Una aplicación de navegación utiliza un proceso de búsqueda típico, en el que el agente (la parte pensante del programa) recibe como datos de entrada tu ubicación actual y tu destino deseado y, basándose en un algoritmo de búsqueda, devuelve un camino sugerido. Sin embargo, hay muchas otras formas de problemas de búsqueda, como rompecabezas o laberintos.\n",
    "\n",
    "Para encontrar la solución a un 15 rompecabezas habría que utilizar un algoritmo de búsqueda.\n",
    "\n",
    "<center><img src=\"../img/SearchPuzzle.jpeg\"/></center>\n",
    "\n",
    "- **Agente**: Entidad que percibe su entorno y actúa sobre él. En una aplicación de navegación, por ejemplo, el agente sería la representación de un coche que debe decidir qué acciones realizar para llegar a su destino.\n",
    "- **Estado**: Configuración de un agente en su entorno. Por ejemplo, en un puzzle del 15, un estado es cualquier forma en la que todos los números están dispuestos en el tablero.\n",
    "- **Acciones**: Opciones que se pueden tomar en un estado. Más concretamente, al recibir el estado s como entrada, Actions(s) devuelve como salida el conjunto de acciones que se pueden ejecutar en el estado s.\n",
    "\n",
    "Un problema puede definirse formalmente por cinco componentes: \n",
    "- **Estado inicial**: Estado del que parte el algoritmo de búsqueda. En una aplicación de navegación, sería la ubicación actual.\n",
    "- **Función sucesor**: Una descripción de qué estado resulta de realizar cualquier acción aplicable en cualquier estado. Más concretamente, al recibir el estado s y la acción a como entrada, Results(s, a) devuelve el estado resultante de realizar la acción a en el estado s.\n",
    "- **Estados o espacio de estados**: Conjunto de todos los estados alcanzables desde el estado inicial mediante cualquier secuencia de acciones. El espacio de estados puede visualizarse como un grafo dirigido con estados, representados como nodos, y acciones, representadas como flechas entre nodos.\n",
    "\n",
    "<center><img src=\"../img/SearchPuzzle2.jpeg\"/></center>\n",
    "\n",
    "- **Función objetivo**: Condición que determina si un estado dado es un estado objetivo.\n",
    "- **Coste del camino**: Coste numérico asociado a una ruta determinada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resolución de problemas de búsqueda**\n",
    "\n",
    "- **Solución**: Secuencia de acciones que dirigen el sistema desde un estado inicial a un estado que verifique la prueba objetivo.\n",
    "- **Solución óptima**: Solución que tiene el menor coste de camino entre todas las soluciones.\n",
    "\n",
    "> Nota: No confundir unicidad de la solución con solución óptima. La solución óptima es aquella que tiene el costo más pequeño, pero puede haber muchas más soluciones que tengan el mismo costo. \n",
    "\n",
    "\n",
    "**_Búsqueda de soluciones_**\n",
    "\n",
    "Esto se hace mediante búsqueda a través del espacio de estados. Nos centraremos en búsquedas que utilizan un **árbol de búsqueda** explícito generado por el estado inicial (nodo) y la función sucesor, definiendo así el espacio de estados. En general, podemos tener un **grafo de búsqueda** más que un árbol, cuando el mismo estado puede alcanzarse desde varios caminos.\n",
    "\n",
    "En un proceso de búsqueda, los datos suelen almacenarse en los nodos de un árbol o grafo de búsqueda, una estructura de datos, donde cada nodo contiene los siguientes datos:\n",
    "- Un estado.\n",
    "- Su nodo padre, a través del cual se generó el nodo actual.\n",
    "- La acción que se aplicó al estado del padre para llegar al nodo actual.\n",
    "- El coste del camino desde el estado inicial hasta este nodo.\n",
    "\n",
    "Los nodos contienen información que los hace muy útiles para los algoritmos de búsqueda. Contienen un estado, que se puede comprobar mediante el test objetivo para ver si es el estado final. Si lo es, el coste del camino del nodo puede compararse con los costes de los caminos de otros nodos, lo que permite elegir la solución óptima,\n",
    "\n",
    "Sin embargo, los nodos son simplemente una estructura de datos: no buscan, sino que guardan información. Para buscar realmente, utilizamos **estrategia de búsqueda**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Estrategias de búsqueda no informada <a class=\"anchor\" id=\"t2_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las estrategias de **búsqwueda no informada** (llamada también **búsqueda a ciegas**) englobadas cinco estrategias de búsqueda. El término significa que ellas no tienen información adicional acerca de los estados más allá de la que proporciona la definición del problema. Todo lo que ellas pueden hacer es generar los sucesores y distinguir entre un estado objetivo de uno que no lo es. Las estrategias que saben si un estado no objetivo es «más prometedor» que otro se llaman **búsqueda informada** o **búsqueda heurística**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Búsqueda en profundidad (Depth-First Search)**\n",
    "\n",
    "Un algoritmo de búsqueda en profundidad agota cada una de las direcciones antes de intentar otra dirección. Siempre expande el nodo más profundo en la frontera actual del árbol de búsqueda. \n",
    "\n",
    "> Frontera: Colección de nodos que se han generado pero todavía no se han expandido.\n",
    "\n",
    "Cuando esos nodos se expanden, son quitados de la frontera, así entonces la búsqueda retrocede al siguiente nodo más superficial que todavía tenga sucesores inexplorados. En estos casos, la frontera se gestiona como una estructura de datos en en pila LIFO (último en entrar primero en salir). \n",
    "\n",
    "<center><img src=\"../img/BProfundidad.jpeg\"/></center>\n",
    "\n",
    "Búsqueda primero en profundidad sobre un árbol binario. Los nodos que se han expandido y no tienen descendientes en la frontera se pueden quitar de la memoria; estos se muestran en negro. Los nodos a profundidad 3 se suponen que no tienen sucesores y M es el nodo objetivo\n",
    "\n",
    "Ventajas:\n",
    "- En el mejor de los casos, este algoritmo es el más rápido. Si \"tiene suerte\" y siempre elige el camino correcto hacia la solución (por casualidad), entonces la búsqueda en profundidad es la que menos tiempo tarda en llegar a la solución.\n",
    "Contras:\n",
    "- Es posible que la solución encontrada no sea óptima.\n",
    "- En el peor de los casos, este algoritmo explorará todos los caminos posibles antes de encontrar la solución, por lo que tardará el mayor tiempo posible en llegar a ella."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Búsqueda en anchura (Breadth-First Search)**\n",
    "\n",
    "La búsqueda en anchura es una estrategia sencilla en la que se expande primero el nodo raíz, a continuación se expanden todos los sucesores del nodo raíz, después sus sucesores, etc.\n",
    "\n",
    "La frontera es una estructura de cola FIFO (Primero en entrar, primero en salir). La cola FIFO pone todos los nuevos sucesores generados al final de la cola, lo que significa que los nodos más superficiales se expanden antes que los nodos más profundos. \n",
    "\n",
    "\n",
    "<center><img src=\"../img/BAnchura.jpeg\"/></center>\n",
    "\n",
    "Búsqueda primero en anchura sobre un árbol binario sencillo. En cada etapa, el próximo nodo a expandir se indica con una marca.\n",
    "\n",
    "Ventajas:\n",
    "- Este algoritmo garantiza encontrar la solución óptima.\n",
    "Desventajas:\n",
    "- Está casi garantizado que este algoritmo tarda más que el tiempo mínimo en ejecutarse.\n",
    "- En el peor de los casos, este algoritmo tarda el mayor tiempo posible en ejecutarse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Búsquedade costo uniforme**\n",
    "\n",
    "En vez de expandir el nodo más superficial, la búsquedade costo uniforme expande el nodo n con el camino de costo más pequeño. Notemos que, si todos los costos son iguales, es idéntico a la búsqueda en anchura. La búsqueda de costo uniforme no se preocupa por el número de pasos que tiene un camino, pero sí sobre su coste total. Podemos garantizar completitud si el costo de cada paso es  mayor o igual a alguna constante positiva pequeña e. Esta condiciónes también suficiente para asegurar optimización. Significa que el costo de un camino siempre aumenta cuando vamos por él. De esta propiedad, es fácil ver que el algoritmo expande nodos que incrementan el coste del camino. Por lo tanto, el primer nodo objetivo seleccionado para la expansión es la solución óptima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Búsqueda en profundidad acotada**\n",
    "\n",
    "Busca aliviar el problema de árboles ilimitados aplicando la búsquedaacotada en profundidad con un límitede profundidad L predeterminado. Es decir, los nodos a profundidad L se trataráncomo si no tuvieran ningúnsucesor. El límitede profundidad resuelve  el problema del camino infinito. Lamentablemente, tambiénintroduce una fuente adicional de incompletitud si escogemos un L < d, es decir, el objetivo está fuera del límite de profundidad.\n",
    "\n",
    "A veces, los límitesde profundidad puedenestar basados en el conocimiento del problema. Este número, conocido como **diámetro del espacio de estados**, nos da un mejor límitede profundidad, que conduce a una búsquedacon profundidad limitada más eficiente. Para la mayor parte de problemas, sin embargo, no conoceremos un límitede profundidad bueno hasta que hayamos resuelto el problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Búsqueda en profundidad iterativa**\n",
    "\n",
    "La búsqueda en profundidad iterativa es una estrategia que encuentra el mejor límite de profundidad. Esto se consigue aumentando gradualmente el límite (primero 0, después 1, después 2, etcétera) hasta que encontramos un objetivo. \n",
    "\n",
    "La búsqueda en profundidad iterativa combina las ventajas de la búsqueda en profundidad simple y la búsqueda en anchura. \n",
    "\n",
    "En la búsqueda en profundidad, sus exigencias de memoria son muy modestas: O(bd). La búsqueda en anchura es completa cuando el factor de ramificación es finito y óptima cuando el coste del camino es una función que no disminuye con la profundidad del nodo. \n",
    "\n",
    "<center><img src=\"../img/BProfundidadIterativa.jpeg\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resumen búsquedas no informadas**\n",
    "\n",
    "<center><img src=\"../img/EstrategiasBusqueda.jpeg\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evitar estados repetidos**\n",
    "\n",
    "Hasta este punto, casi hemos ignorado una de las complicaciones más importantes al proceso de búsqueda: la posibilidad de perder tiempo expandiendo estados que ya han sido visitados y expandidos. \n",
    "\n",
    "Para algunos problemas, esta posibilidad nunca aparece, el espacio de estados es un árbol y hay sólo un camino a cada estado. Para otros es inevitable, esto incluye todos los problemas donde las acciones son reversibles, como son los problemas de búsqueda de rutas y los puzles que deslizan sus piezas. Los árboles de la búsqueda para estos problemas son infinitos.\n",
    "\n",
    "Entonces, si el algoritmo no detecta los estados repetidos, éstos pueden provocar que un problema resoluble llegue a ser irresoluble. La detección por lo general significa la comparación del nodo a expandir con aquellos que han sido ya expandidos; si se encuentra\n",
    "un emparejamiento, entonces el algoritmo ha descubierto dos caminos al mismo estado y puede desechar uno de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Búsqueda con información parcial**\n",
    "\n",
    "Partimos desde un supuesto de que el entorno es totalmente observable y determinista y que el agente conoce cuáles son los efectos de cada acción. Por lo tanto, el agente puede calcular exactamente cuál es el estado resultado de cualquier secuencia de acciones y siempre sabe en qué estado está. Su percepción no proporciona ninguna nueva información después de cada acción. \n",
    "\n",
    "_¿Qué pasa cuando el conocimiento de los estados o acciones es incompleto?_\n",
    "\n",
    "Encontramos que diversos tipos de incompletitud conducen a tres tipos de problemas distintos:\n",
    "- **Problemas sin sensores** (también llamados problemas conformados): Si el agente no tiene ningún sensor, entonces (por lo que sabe) podría estar en uno de los posibles estados iniciales, y cada acción por lo tanto podría conducir a uno de los posibles estados sucesores.\n",
    "- **Problemas de contingencia**: Si el entorno es parcialmente observable o si las acciones son inciertas, entonces las percepciones del agente proporcionan nueva información después de cada acción. Cada percepción posible define una contingencia que debe de planearse. A un problema se le llama entre adversarios si la incertidumbre está causada por las acciones de otro agente.\n",
    "- **Problemas de exploración**: Cuando se desconocen los estados y las acciones del entorno, el agente debe actuar para descubrirlos. Los problemas de exploración pueden verse como un caso extremo de problemas de contingencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Estrategias de búsqueda informada y exploración <a class=\"anchor\" id=\"t2_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las estrategias de búsqueda **no informadas** pueden encontrar soluciones a problemas generando sistemáticamente nuevos estados y evaluando hasta alcanzar un objetivo. \n",
    "\n",
    "Lamentablemente, estas estrategias son increíblemente ineficientes en la mayoría de casos:\n",
    "- No consideran informción sobre estados y objetivos para decidir que camino expandir primero en la frontera.\n",
    "- Son estrategias generales y no consideran características específicas del problema.\n",
    "- Los algoritmos de busqueda no tienen en cuenta el objetivo hasta que están en el nodo objetivo.\n",
    "- En algunos problemas, existe información extra que puede ser usadapara guiar la búsqueda.\n",
    "\n",
    "Una estrategia de **búsqueda informada** puede encontrar soluciones de una manera más eficiente que una estrategia no informada. A la aproximación general se le conoce como **búsqueda primero el mejor**, que es un caso particular del algoritmo general de búsqueda-árboles o de búsqueda-grafos en el cual se selecciona un nodo para la expansión basada en una **función de evaluación**. Se implementa con con una cola con prioridad, expandiendo así siempre el nodo de la frontera que parece ser mejor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Búsqueda voraz primero el mejor**\n",
    "\n",
    "La búsqueda voraz primero el mejor trata de expandir el nodo más cercano al objetivo, alegando que probablemente conduzca rápidamente a una solución. Así, evalúa los nodos utilizando solamente la función heurística f(n) = h(n) en cada nodo, la función estima lo cerca de la meta que está el siguiente nodo. La eficacia del algoritmo depende de la calidad de la función heurística.\n",
    "\n",
    "_Ejemplo:_\n",
    "\n",
    "La siguiente figura muestra el progreso de una búsqueda primero el mejor voraz con hDLR para encontrar un camino desde Arad a Bucarest. El primer nodo a expandir desde Arad será Sibiu, porque está mas cerca de Bucarest que Zerind o Timisoara. El siguiente nodo a expandir será Fagaras, porque es la más cercana. Fagaras en su turno genera Bucarest, que es el objetivo. \n",
    "\n",
    "<center><img src=\"../img/BVoraz.jpeg\"/></center>\n",
    "\n",
    "_Propiedades:_\n",
    "- Completa: No, puede quedarse atascada en bucles. Completa en un espacio finito con comprobación de estados repetidos.\n",
    "- Temporal: O(b^m), pero una buena heurística puede mejorarla mucho.\n",
    "- Espacio: O(b^m), porque mantiene todos los nodos en memoria.\n",
    "- Optima: No."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-Búsqueda A\\*: Minimiza el costo estimado total de la solución**\n",
    "\n",
    "La búsqueda A*, una evolución del algoritmo de búsqueda del mejor primero, tiene en cuenta lo siguiente: \n",
    "\n",
    ">   f(n) = **g(n) + h(n)** <= C*\n",
    "\n",
    "- h(n): El coste estimado desde la posición actual hasta la meta.\n",
    "- g(n): El coste acumulado hasta la posición actual.\n",
    "- f(n): El coste estimado total del camino que llega al objetivo pasando por n.\n",
    "- C*: El coste de la supuesta solución óptima.\n",
    "\n",
    "Al combinar ambos valores, el algoritmo dispone de una forma más precisa de determinar el coste de la solución y optimizar sus elecciones sobre la marcha. El algoritmo lleva la cuenta de (coste del camino hasta ahora + coste estimado hasta la meta), y una vez que supera el coste estimado de alguna opción anterior, el algoritmo abandona el camino actual y vuelve a la opción anterior, evitando así recorrer un camino largo e ineficiente que h(n) marcó erróneamente como el mejor.\n",
    "\n",
    "_Ejemplo:_\n",
    "\n",
    "<center><img src=\"../img/BusquedaA.jpeg\"/></center>\n",
    "\n",
    "Las heurísticas admisibles son por naturaleza optimistas, porque piensan que el coste de resolver el problema es menor que el que es en realidad. Ya que g(n) es el coste exacto para alcanzar n, tenemos como consecuencia inmediata que la f(n) nunca sobre estima el coste verdadero de una solución a través de n. \n",
    "\n",
    "_Propiedades:_\n",
    "- Completa: Sí, a menos que existan infinitos nodos con f<= f(G).\n",
    "- Temporal: Exponencial.\n",
    "- Espacio: O(b^m), mantiene todos los nodos en memoria.\n",
    "- Optima: Si."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funciones Heurísticas**\n",
    "\n",
    "Una heurística h(n) es consistente si, para cada nodo n y cada sucesor n’ de n generado por cualquier acción a, el coste estimado de alcanzar el objetivo desde n no es mayor que el coste de alcanzar n’ más el coste estimado de alcanzar el objetivo desde n’.\n",
    "\n",
    "> h(n) <= c(n,a,n’) + h(n’)\n",
    "\n",
    "Es decir,h(n) es menor o igual que el coste de cualquier camino desde n hasta el objetivo. Una heurística admisible nunca sobrestima el coste real de alcanzar una solución.\n",
    "\n",
    "_Heurística admisible_\n",
    "\n",
    "<center><img src=\"../img/HeuristicaAdmisible.jpeg\"/></center>\n",
    "\n",
    "- Si h2(n) ≥ h1(n) para todos los n (ambas admisibles) entonces h2 domina a h1.  En este caso, h2 es mejor para la búsqueda.\n",
    "- Costes de búsqueda típicos (número medio de nodos expandidos).\n",
    "- Dadas dos heurísticas admisibles ha,hb: h(n) = max(ha(n), hb(n))\n",
    "\n",
    "_Problemas relajados_\n",
    "- Un problema con menos restricciones en las acciones se denomina **problema relajado**.\n",
    "- El coste de una solución óptima en un problema relajado es una heurística admisible para el problema original.\n",
    "- **Clave**: El costo de la solución ́optima de un problema relajadono es mayor que el costo de la solución óptima del problema real.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Algoritmos de búsqueda local y problemas de optimización <a class=\"anchor\" id=\"t2_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los algoritmos de búsquedaqua vistos hasta ahora se diseñan para explorar sistemáticamente espacios de búsqueda. Esta forma sistemática se alcana manteniendo uno o más caminos en memoria y registrando que alternativas se han explorado en cada punto o a lo largo del camino y cuáles no.\n",
    "\n",
    "Si no importa el camino al objetivo, podemos considerar una clase diferente de algoritmos, que no se preocupen en absoluto de los caminos. Los algoritmos de **búsqueda local** funcionan con un solo **estado actual** que se va optimizando. En este tipo de problemas, lo que interesa es encontrar el mejor estado (solución) de acuerdo con una función objetivo. En este sentido, el espacio de estados está formado por un conjunto completo de configuraciones que cumplen la función objetivo. \n",
    "\n",
    "Los algoritmos de búsqueda local no son sistemáticos, pero presentan dos ventajas claves:\n",
    "- Usan muy poca memoria.\n",
    "- Pueden encontrar a menudo soluciones razonables en espacios de estados grandes o infinitos para los cuales los algoritmos sistemáticos son inadecuados.\n",
    "\n",
    "Por estas ventajas, los algoritmos de **búsqueda local** son útiles para resolver problemas de **optimización**, en los cuales el objetivo es encontrar el mejor estado según una **función objetivo**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Ascensión de colinas**\n",
    "\n",
    "El algoritmo de ascensión de colinas parte de una solución y busca soluciones vecinas, de forma que coge la mejor solución vecina y la compara con la solución actual. Si la solución vecina es mejor pasa a ser la solución actual, repitiendo el proceso. Si la mejor solución vecina no mejora a la solución actual el proceso para, devolviendo la solución actual. \n",
    "\n",
    "El algoritmo de ascensión de colina es simplemente un bucle que continuamente se mueve en dirección del valor creciente, es decir, cuesta arriba. Termina cuando alcanza un pico en donde ningún vecino tiene un valor más alto. El algoritmo no mantiene un árbol de búsqueda, sino una estructura de datos del nodo actual que sólo necesita el registro del estado y su valor de función objetivo. \n",
    "\n",
    "Lamentablemente, la ascensiónde colinas a menudo se atasca por los siguientes motivos:\n",
    "- Máximo local: Un máximo local es un pico que es más alto que cada uno de sus estados vecinos pero más bajo que el máximo global.\n",
    "- Crestas: Las crestas causan una secuencia de máximos locales que hace muy difícil la navegación para los algoritmos avaros.\n",
    "- Meseta: Una meseta es un área del paisaje del espacio de estados donde la función de evaluación es plana.\n",
    "\n",
    "<center><img src=\"../img/BusquedaLocal.jpeg\"/></center>\n",
    "\n",
    "Para entender esto, consideramos la forma o el paisaje del espacio de estados, que tiene «posición» (definido por el estado) y «elevación» (definido por el valor de la función de coste heurística o función objetivo). Si la elevación corresponde al costo, entonces el objetivo es encontrar el valle más bajo (un mínimo global); si la elevación corresponde a una función objetivo, entonces el objetivo es encontrar el pico más alto (un máximo global)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Búsqueda por haz local**\n",
    "\n",
    "Guardar solamente un nodo en la memoria podría parecer una reacción extrema para el problema de limitaciones de memoria. El algoritmo de búsqueda por haz local guarda la pista de k estados (no sólo uno). Comienza por k estados (soluciones) generados aleatoriamente. \n",
    "\n",
    "En cada iteración se generan todos los estados sucesores de los k estado. Si alguno es un objetivo, entonces para. Si no, elige los mejores k sucesores de la lista completa de sucesores y repite el ciclo. \n",
    "\n",
    "El problema es que los k mejores sucesores tienen a estar en la misma zona. Como solución, se pueden elegir aleatoriamente los k mejores sucesores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Algoritmos Genéticos**\n",
    "\n",
    "Un algoritmo genético es una variante de la búsqueda de haz en la que los estados sucesores se generan combinando dos estados padres.\n",
    "\n",
    "Como en la búsqueda de haz, los algoritmos genéticos comienzan con un conjunto de k estados generados aleatoriamente, llamados población. Cada estado, o individuo, está representado como una cadena sobre un alfabeto finito (normalmente cadenas de 1s o 0s).\n",
    "\n",
    "Cada estado está tasado con una función idoneidad, la cual debería devolver valores más altos para estados mejores.\n",
    "\n",
    "En (c) se seleccionan dos pares, de manera aleatoria, para la reproducción, de acuerdo con las probabilidades en (b).  Notemos que un individuo se selecciona dos veces y uno ninguna. Para que cada par se aparee, se elige aleatoriamente un punto de cruce de las posiciones en la cadena. \n",
    "\n",
    "En (d) los descendientes se crean cruzando las cadenas paternales en el punto de cruce. Por ejemplo, el primer hijo del primer par consigue los tres primeros dígitos del primer padre y los dígitos restantes del segundo padre. \n",
    "\n",
    "<center><img src=\"../img/BAlgoGeneticos.jpeg\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Problemas de satisfacción de restricciones<a class=\"anchor\" id=\"t3\"></a>\n",
    "![title](../img/Divider.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora se explora la idea de que los problemas pueden resolverse buscando en un espacio de estados. Estos estados pueden evaluarse con heurísticas específicas del dominio y probados para ver si son estados objetivo. Desde el punto de vista del\n",
    "algoritmo de búsqueda, sin embargo, cada estado es una **caja negra** que se representa por una estructura de datos arbitraria a la que se puede acceder sólo con las rutinas.\n",
    "\n",
    "Los **problemas de satisfacción de restricciones** (PSR) ofrecen varias ventajas importantes. Dado que la representación del estado se ajusta a un modelo estándar, es decir, un conjunto de variables con valores asignados, tanto la función sucesora como la prueba de objetivo pueden escribirse de manera genérica, aplicable a cualquier PSR. Además, podemos desarrollar heurísticas eficaces y genéricas que no requieren información adicional o conocimiento experto del dominio específico. Finalmente, la estructura del grafo de restricciones puede utilizarse para simplificar el proceso de solución, lo que en algunos casos puede resultar en una reducción exponencial de la complejidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Problemas de satisfacción de restricciones <a class=\"anchor\" id=\"t3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formalmente, un **problema de satisfacción de restricciones** (o **PSR**) está definido por\n",
    "- Un conjunto de **variables**, V1, V2…, Vn. Cada variable Vi tiene un dominio no vacío Dvi de valores posibles.\n",
    "- Un conjunto de **restricciones fuertes**, R1, R2…, Rm. Cada restricción Ri implica un subconjunto de variables y especifica las combinaciones aceptables de valores para ese subconjunto.\n",
    "\n",
    "Un estado del problema está definido por una asignación de valores a unas o todas (*formulación completa de estados*) las variables, {Vi = xi, Vj = xj…}. \n",
    "\n",
    "Buscamos una asignación de las variables que verifique la asignación objetivo.\n",
    "- **Verificación**: Debe cumplir unas restricciones entre los valores de las variables.\n",
    "- **Satisfacción de restricciones**: Las verificaciones nos dan la parte de especificidad del problema, cuanto más restricciones más especificidad.\n",
    "- **Asignación consistente o legal**: Es una asignación que no viola ninguna restricción.\n",
    "- **Asignación completa**: Es una asignación en la que se menciona cada variable.\n",
    "- **Solución o modelo**: Es una asignación de valores a todas sus variables que satisface todas las restricciones.\n",
    "Algunos\tproblemas de satisfacción de restricciones PSR\ttambién\trequiere una solución que maximiza una **función objetivo**.\n",
    "\n",
    "En estos problemas la **profundidad** viene dada por la cantidad de acciones (asignaciones) y el dominio nos da el **nivel de ramificación**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos, por ejemplo, un mapa de Australia que muestra cada uno de sus estados y territorios. Supongamos que se nos asigna la tarea de colorear cada región en rojo, verde o azul, de tal manera que ninguna región adyacente tenga el mismo color. Para formular esto como un Problema de Satisfacción de Restricciones (PSR), definimos variables para las regiones: AQ, TN, Q, NGS, V, AS y T. El dominio de cada variable es el conjunto {rojo, verde, azul}. Las restricciones exigen que las regiones vecinas tengan colores distintos.\n",
    "\n",
    "![title](../img/PRSAustralia.JPG)\n",
    "\n",
    "Es bueno visualizar\tun PSR como\tun **grafo de restricciones**, donde los nodos del grafo corresponden a\tlas\tvariables del problema y los arcos corresponden\ta las restricciones.\n",
    "\n",
    "- Varbles: WA, NT, Q, NSW, V, SA, T.\n",
    "- Dominios: {red, green, blue}.\n",
    "- Restricciones: Regiones adyacentes deben tener colores diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clases de problemas y tipos de restricciones**\n",
    "\n",
    "*Tipos de problemas*\n",
    "- La clase más simple de PSR implica variables *discretas* y *dominios finitos*\n",
    "- Las variables discretas también pueden tener dominios infinitos, implican el uso de *lenguaje de restricciones*.\n",
    "\n",
    "*Tipos de restricciones*\n",
    "- Unarias: Restringe los valores de una sola variable, por ejemplo SA *not* green.\n",
    "- Binarias: Afecta a pares de variables, por ejemplo SA not WA.\n",
    "- N-Arias: Afectan a o más variables, por ejemplo AllDiff.\n",
    "\n",
    "**Alcance:** El alcance se refiere al conjunto de variables involucradas en una restricción.\n",
    "\n",
    "**Preferencias:** (restricciones blandas): Las restricciones blandas son aquellas cuya violación no impide encontrar una solución, pero su cumplimiento es deseable para mejorar la calidad de la solución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Búsqueda con vuelta atrás para PSR <a class=\"anchor\" id=\"t3_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La \"búsqueda con vuelta atrás\" es un enfoque de búsqueda primero en profundidad que selecciona secuencialmente valores para una variable, retrocediendo cuando una variable no tiene valores legales asignables. Aunque es un algoritmo sin información y puede no ser eficiente en problemas grandes, su metodología es fundamental en la resolución de ciertos tipos de problemas (Generación de horarios, Configuración de Hardware, Planificación en transporte, Floorplanning...).\n",
    "\n",
    "![title](../img/PSRBacktracking.JPG)\n",
    "\n",
    "**Mejorando la eficiencia del backtracking**\n",
    "- ¿Qué variable debería asignar la siguiente?\n",
    "    - Pueden ser usadas una o más **heurísticas**, por ejemplo la variable mas restrictiva (Si falla que sea lo más pronto posible).\n",
    "- ¿En qué orden deberéan sus valores ser probados?\n",
    "    - Decidir sobre que valores considerar primero.\n",
    "- ¿Se podrían detectar fallos inevitables de manera temprana?\n",
    "    - Se puede realizar durante el proceso de búsqueda proporcionando una guía.\n",
    "- ¿Se podría sacar ventaja de la estructura del problema?\n",
    "    - Analizar la estructura del problema puede revelar patrones o dependencias.\n",
    "\n",
    "La heurística de **Mínimos Valores Restantes (MVR)**, también conocida como la heurística \"variable más restringida\" o \"primero en fallar\", escoge una variable que con mayor probabilidad (variable con menos valores «legales») causará pronto un fracaso, con lo cual podamos el árbol de búsqueda.\n",
    "\n",
    "La heurística de **Mínimo Grado Restante** \"grado heurístico\" (Degree heuristic), está heurístico es más práctica en la primera elección porque al principio todas las variables tienen valores legales. Intenta reducir el factor de ramificación sobre futuras opciones seleccionando la variable, entre las variables no asignadas, que esté implicada en el mayor número de restricciones, es una guía más menos poderosa, pero puede ser útil en caso de desempate MVR.\n",
    "\n",
    "Una vez que se selecciona una variable, el algoritmo debe decidir el **orden** para examinar sus valores. Para esto, la heurística del **Valor Menos Restringido** puede ser eficaz en algunos casos. Se prefiere el valor que excluye las pocas opciones de las variables vecinas en el grafo de restricciones. La heurística trata de dejar la flexibilidad máxima de las asignaciones de las variables siguientes, esto es útil si queremos encontrar todas las posibles soluciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Propagación de la información a través de las restricciones**\n",
    "\n",
    "Hasta ahora, nuestro algoritmo de búsqueda solo toma en cuenta las restricciones asociadas a una variable en el momento en que dicha variable es seleccionada. Sin embargo, al considerar algunas restricciones antes en el proceso de búsqueda, o incluso antes de que la búsqueda comience, es posible reducir de manera significativa el espacio de búsqueda. Es fundamental que este proceso sea rápido, para no aumentar el tiempo total de búsqueda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comprobación hacia delante**\n",
    "\n",
    "Otra manera para usar mejor las restricciones durante la búsqueda se llama comprobación hacia delante. Siempre que se asigne una variable X, el proceso de comprobación hacia delante mira cada variable no asignada Y que esté relacionada con X por una relación, y suprime del dominio de Y cualquier valor que sea inconsistente con el valor elegido para X.\n",
    "\n",
    "![title](../img/PRSCHD.JPG)\n",
    "\n",
    "Hay dos puntos importantes que debemos destacar sobre este ejemplo. Primero, notemos que después de asignar AQ = rojo y Q = verde, los dominios de TN y AS se reducen a un solo valor; hemos eliminado las ramificaciones de estas variables totalmente propagando la información de AQ y Q. La heurística MVR, la cual es una compañera obvia para la comprobación hacia delante, seleccionaría automáticamente AS y TN después (en efecto, podemos ver como la comprobación hacia delante como un modo eficiente de incrementar el cálculo de la información que necesita la heurística MVR para hacer su trabajo). Un segundo punto a tener en cuenta es que, después de V = azul, el dominio de SA está vacío. Por eso, la comprobación hacia delante ha descubierto que la asignación parcial {AQ = rojo, Q = verde, V = azul} es inconsistente con las restricciones del problema, y el algoritmo volverá atrás inmediatamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arcos Consistentes**\n",
    "\n",
    "La técnica de \"arco consistente\" es un método eficaz de propagación de restricciones que es más poderoso que la comprobación hacia delante. Consiste en asegurarse de que para cada valor posible de una variable, haya una asignación consistente en las variables relacionadas.\n",
    "\n",
    "- Idea: Podar los dominios tanto como sea posible antes de seleccionar valores.\n",
    "- Variable es consistente con su dominio: Ningún valor del dominio del nodo es clasificado como imposible por ninguna de las restricciones.\n",
    "- Fácil de identificar en restricciones unarias pero muy complicado en k-arias.\n",
    "\n",
    "\n",
    "**Red de Restricciones**\n",
    "- Hay un nodo ovalado para cada variable.\n",
    "- Hay un nodo rectangular para cada restricción.\n",
    "- Hay un dominio de valores asociado a cada nodo.\n",
    "- Hay un arco desde cada variable X a cada restricción que involucra a X.\n",
    "\n",
    "![title](../img/PSRRdR.JPG)\n",
    "\n",
    "- Un arco es consistente: Se dice que es consistente si para cada valor posible de X (x) hay al menos un valor en Y (y) que cumpla con la regla r(x, y).\n",
    "- Una red es arco consistente si todos sus arcos son consistentes.\n",
    "- Si se encuentra un arco que no es consistente (es decir, hay valores en X para los cuales no hay valores correspondientes compatibles en Y), se puede hacer consistente eliminando esos valores problemáticos del conjunto de posibles valores de X.\n",
    "\n",
    "![title](../img/PSRArco.JPG)\n",
    "\n",
    "La comprobación de la consistencia de arcos puede implementarse tanto como un paso de preproceso antes de iniciar la búsqueda, como también durante la búsqueda, similar a la comprobación hacia delante, después de cada asignación. El algoritmo completo para mantener la consistencia de arcos, conocido como AC-3, utiliza una cola para administrar los arcos pendientes de revisión. Cada arco (Xi, Xj) se examina para determinar si es necesario eliminar valores del dominio de Xi; si es así, todos los arcos que apuntan a Xi se agregan de nuevo a la cola para ser reevaluados.\n",
    "\n",
    "Un grafo es fuertemente k-consistente si cumple con la condición de k-consistencia y todas las condiciones de consistencia inferiores, es decir, (k-1)-consistencia, (k-2)-consistencia, y así sucesivamente, hasta 1-consistencia.\n",
    "\n",
    "![title](../img/PSRAC3.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Resolución por Búsqueda Local <a class=\"anchor\" id=\"t3_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los algoritmos de búsqueda local son muy efectivos para resolver muchos Problemas de Satisfacción de Restricciones (PSR). Utilizan una formulación de estado completa, donde el estado inicial asigna un valor a cada variable y la función sucesora cambia el valor de una variable a la vez. Por ejemplo, en el problema de las 8-reinas, se podría comenzar con una configuración aleatoria de las reinas y mover una reina a otra posición en su columna como sucesor.\n",
    "\n",
    "![title](../img/PSRMinConflictos.JPG)\n",
    "\n",
    "Una estrategia común en la búsqueda local es seleccionar el nuevo valor de una variable que cause el mínimo de conflictos con otras variables, conocida como la heurística de mínimos conflictos. Esta heurística ha demostrado ser sorprendentemente efectiva, especialmente si el estado inicial es razonablemente bueno.\n",
    "\n",
    "Interesantemente, en el problema de las n-reinas, el tiempo de ejecución del algoritmo de mínimos conflictos es casi independiente del tamaño del problema, resolviendo problemas de hasta un millón de reinas en un promedio de 50 pasos después de la asignación inicial.\n",
    "\n",
    "![title](../img/PSRMinConReinas.JPG)\n",
    "\n",
    "Este hallazgo fue un estímulo clave en la investigación de los años 90 sobre la búsqueda local y la distinción entre problemas fáciles y difíciles. En términos generales, el problema de las n-reinas es más accesible para la búsqueda local porque las soluciones están densamente distribuidas en el espacio de estados. La heurística de mínimos conflictos también es efectiva en problemas más desafiantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Búsqueda entre adversarios <a class=\"anchor\" id=\"t4\"></a>\n",
    "![title](../img/Divider.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los agentes deben considerar las acciones de otros y su impacto en su propio bienestar. La imprevisibilidad de otros agentes añade complejidad al proceso de resolución de problemas. Se distingue entre entornos multiagente cooperativos y competitivos, siendo los últimos un escenario para problemas de búsqueda entre adversarios o juegos.\n",
    "\n",
    "La teoría de juegos, una rama de la Economía, considera cualquier entorno multiagente como un juego, siempre que la influencia entre agentes sea significativa. En Inteligencia Artificial, los juegos suelen referirse a una categoría más específica, como juegos de suma cero y de dos jugadores, donde los valores de utilidad al final del juego son opuestos para cada jugador.\n",
    "\n",
    "Los juegos son un área de interés en IA debido a su naturaleza abstracta y reglas definidas. Han sido un foco desde los inicios de la IA, con avances significativos en juegos como ajedrez y damas. A pesar de su aparente simplicidad, los juegos representan desafíos complejos y sirven para desarrollar técnicas como la poda y evaluaciones heurísticas, aplicables en situaciones donde no es factible calcular la decisión óptima. El capítulo explora también juegos con elementos de azar e información imperfecta, y concluye examinando el rendimiento de los programas de IA en juegos contra humanos y posibles direcciones futuras de investigación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Decisiones\tóptimas <a class=\"anchor\" id=\"t4_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideramos juegos\tcon\tdos\tjugadores, que llamaremos MAX y\tMIN\tpor\tmotivos\tque\tpronto se harán evidentes. MAX mueve primero, y\tluego mueven por turno hasta que el juego termina. Al final del juego, se conceden puntos al jugador ganador y penalizaciones al perdedor. Un juego puede definirse\tformalmente\tcomo una clase de problemas\tde búsqueda\tcon\tlos\tcomponentes\tsiguientes:\n",
    "- El **estado inicial**, que incluye la posición del tablero e identifica al jugador que mueve.\n",
    "- Una **función sucesor**, que devuelve una lista de pares (movimiento, estado), indicando un movimiento legal y el estado que resulta.\n",
    "- Un **test terminal**, que determina cuándo se termina el juego. A los estados donde el juego se ha terminado se les llaman estados terminales.\n",
    "- Una **función utilidad** (también llamada función objetivo o función de rentabilidad), que da un valor numérico a los estados terminales (Victoria +1, empate 0, derrota -1).\n",
    "\n",
    "El estado inicial y los movimientos legales para cada lado definen el **árbol de juegos**. La imagen muestra la parte del árbol de juegos para el tres en raya. Desde el estado inicial, MAX tiene nueve movimientos posibles. El juego alterna entre la colocación de una X para MAX y la colocación de un O para MIN, hasta que alcancemos nodos hoja correspondientes a estados terminales, de modo que un jugador tenga tres en raya o todos los cuadros estén llenos. El número sobre cada nodo hoja indica el valor de utilidad del estado terminal desde el punto de vista de MAX.\n",
    "\n",
    "![title](../img/MinMax.JPG)\n",
    "\n",
    "En un problema de búsqueda normal, la solución óptima sería una secuencia de movimientos que conducen a un estado objetivo (un estado terminal que es ganador). En un juego, por otra parte, MIN tiene algo que decir sobre ello. MAX, por lo tanto, debe encontrar una estrategia contingente, que especifica el movimiento de MAX en el estado inicial, después los movimientos de MAX en los estados que resultan de cada respuesta posible de MIN, después de los movimientos de MAX en los estados que resultan de cada respuesta posible de MIN de los anteriores movimientos, etc. Hablando de forma apropiada, una estrategia cuando uno juega con un oponente infalible.\n",
    "\n",
    "Incluso un juego simple como el tres en raya es demasiado complejo para dibujar el árbol de juegos entero, por tanto, cambiemos al juego trivial de la imagen 2. Los movimientos posibles para MAX, en el nodo raíz, se etiquetan por a1, a2 y a3. Las respuestas posibles a a1, para MIN, son b1, b2, b3, etc. Este juego particular finaliza después de un movimiento para MAX y MIN.\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
