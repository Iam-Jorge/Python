{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inteligencia artificial\n",
    "![title](../img/TitleDivider.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1. Introducción](#t1)\n",
    "    - [1.1. ¿Qué es la IA?](#t1_1)\n",
    "    - [1.2. Agentes inteligentes](#t1_2)\n",
    "- [2. Resolver problemas mediante búsqueda](#t2)\n",
    "    - [2.1. Estrategias de búsqueda no informada](#t2_1)\n",
    "    - [2.2. Estrategias de búsqueda informada y exploración](#t2_2)\n",
    "    - [2.3. Algoritmos de búsqueda local y problemas de optimización](#t2_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ¿Introducción? <a class=\"anchor\" id=\"t1\"></a>\n",
    "![title](../img/Divider.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante miles de años, hemos tratado de entender cómo pensamos; es decir, entender cómo un simple puñado de materia puede percibir, entender, predecir y manipular un mundo mucho más grande y complicado que ella misma. El campo de la inteligencia artificial,\n",
    "o IA, va más allá: no sólo intenta comprender, sino que también se esfuerza en construir entidades inteligentes.\n",
    "\n",
    "La IA es una de las ciencias más recientes. El trabajo comenzó poco después de la Segunda Guerra Mundial, y el nombre se acuñó en 1956.\n",
    "\n",
    "La IA abarca en la actualidad una gran variedad de subcampos, la IA **sintetiza y automatiza** tareas intelectuales y es, por lo tanto, potencialmente relevante para cualquier ámbito de la actividad intelectual humana. En este sentido, es un campo genuinamente universal.\n",
    "\n",
    "Una breve historia de las disciplinas que han contribuido con ideas, puntos de vista y técnicas al desarrollo en torno a una serie de cuestiones, con el objetivo último de todas estas disciplinas en hacer avanzar la IA.\n",
    "\n",
    "- Filosofía (desde el año 428 a.C. hasta el presente)\n",
    "- Matemáticas (aproximadamente desde el año 800 al presente)\n",
    "- Economía (desde el año 1776 hasta el presente)\n",
    "- Neurociencia (desde el año 1861 hasta el presente)\n",
    "- Psicología (desde el año 1879 hasta el presente)\n",
    "- Ingeniería computacional (desde el año 1940 hasta el presente)\n",
    "- Teoría de control y cibernética (desde el año 1948 hasta el presente)\n",
    "- Lingüística (desde el año 1957 hasta el presente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Historia (Breve) de la inteligencia artificial**\n",
    "\n",
    "- 1940-1950: Primeros días de la IA●1943: McCulloc & Pitts: Modelo Booleano del Cerebro.\n",
    "    - 1950: Turing: Computing Machinery and Intelligence.\n",
    "- 1950-1970: Mira Mamá, Sin Manos!!\n",
    "    - 1950s: Primeros programas de IA (Samuells, Newell,...)\n",
    "    - 1956: Adopción del término “Inteligencia Artificial”.\n",
    "    - 1965: Algoritmo de Robinson de Razonamiento Lógico.\n",
    "-  1970-1990: Sistemas Basados Conocimiento\n",
    "    - 1970s: Primeros sistemas basados en el Conocimiento.\n",
    "    - 1980s: Boom de los Sistemas Expertos.\n",
    "    - 1993: Pesimismo Sistemas Expertos: AI-Winter.\n",
    "- 1990-Hoy: Aproximaciones Modernas\n",
    "    - Probabilidad, Estadística e Incertidumbre.\n",
    "    - Incremento general en profundidad técnica.\n",
    "    - Agentes , Agentes , Agentes..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. ¿Qué es la IA? <a class=\"anchor\" id=\"t1_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lo largo de la historia se han seguido los cuatro enfoques representados en la siguiente figura:\n",
    "\n",
    "<center><img src=\"../img/AI-Figura1-1.jpeg\"/></center>\n",
    "\n",
    "Las que aparecen en la parte superior se refieren a **_procesos mentales y al razonamiento_**, mientras que los de la parte inferior aluden a la **_conducta_**.\n",
    "Las definiciones de la izquierda miden el éxito en términos de la fidelidad en la forma de actuar de los **_humanos_**, mientras que las de la derecha toman como referencia un concepto ideal de inteligencia, que llamaremos **_racionalidad_**.\n",
    "\n",
    "> Un sistema es racional si hace «lo correcto», en función de su conocimiento.\n",
    "\n",
    "- Piensan como Humanos (Ciencia cognitiva)\n",
    "- Piensan racionalmente (Leyes del pensamiento)\n",
    "- Actúan como humanos (Prueba de Turing)\n",
    "- Actúan Racionalmente (Agente Racional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comportamiento humano: el enfoque de la Prueba de Turing\n",
    "\n",
    "La Prueba de Turing, propuesta por Alan Turing (1950), se diseñó para proporcionar una definición operacional y satisfactoria de inteligencia. En vez de proporcionar una lista larga y quizá controvertida de cualidades necesarias para obtener inteligencia artificialmente, él sugirió una prueba basada en la incapacidad de diferenciar entre entidades inteligentes indiscutibles y seres humanos.\n",
    "\n",
    "El computador supera la prueba si un evaluador (humano) no es capaz de distinguir si las respuestas, a una serie de preguntas planteadas, son de una persona o no.\n",
    "\n",
    "Para superar la prueba de Turing el computador debería poseer las siguientes capacidades:\n",
    "- Procesamiento de lenguaje natural que le permita comunicarse satisfactoriamente en inglés.\n",
    "- Representación del conocimiento para almacenar lo que se conoce o siente.\n",
    "- Razonamiento automático para utilizar la información almacenada para responder a preguntas y extraer nuevas conclusiones.\n",
    "- Aprendizaje automático para adaptarse a nuevas circunstancias y para detectar y extrapolar patrones.\n",
    "\n",
    "El test global añade:\n",
    "- Visión computacional para percibir objetos.\n",
    "- Robótica para manipular y mover objetos.\n",
    "\n",
    "Estas seis disciplinas abarcan la mayor parte de la IA, y Turing merece ser reconocido por diseñar una prueba que se conserva vigente después de 50 años."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pensar como un humano: el enfoque del modelo cognitivo\n",
    "\n",
    "Para poder decir que un programa dado piensa como un humano, es necesario contar con un mecanismo para determinar cómo piensan los humanos. Es necesario penetrar en el funcionamiento de las mentes humanas. Hay dos formas de hacerlo:\n",
    "- Mediante introspección (intentando atrapar nuestros propios pensamientos conforme éstos van apareciendo).\n",
    "- Mediante experimentos psicológicos.\n",
    "\n",
    "Una vez se cuente con una teoría lo suficientemente precisa sobre cómo trabaja la mente, se podrá expresar esa teoría en la forma de un programa de computador.\n",
    "\n",
    "Si los datos de entrada/salida del programa y los tiempos de reacción son similares a los de un humano, existe la evidencia de que algunos de los mecanismos del programa se pueden comparar con los que utilizan los seres humanos. No basta con que el programa resielva correctamente los problemas, lo que interesa es seguir la pista de las etapas del proceso de razonamiento y compararlas con las seguidas por humanos a los que se les enfrentó a los mismos problemas. En el campo de la **_ciencia cognitiva_** convergen modelos computacionales de IA y técnicas experimentales de psicología intentando elaborar teorías precisas y verificables sobre el funcionamiento de la mente humana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pensamiento racional: el enfoque de las «leyes del pensamiento»\n",
    "\n",
    "El filósofo griego Aristóteles fue uno de los primeros en intentar codificar la «manera correcta de pensar», es decir, un proceso de razonamiento irrefutable. Sus silogismos son esquemas de estructuras de argumentación mediante las que siempre se llega a conclusiones correctas si se parte de premisas correctas. (por ejemplo: «Sócrates es un hombre; todos los hombres son mortales; por lo tanto Sócrates es mortal»). Estas leyes de pensamiento supuestamente gobiernan la manera de operar de la mente; su estudio fue el\n",
    "inicio de un campo llamado **_lógica_**.\n",
    "\n",
    "En el siglo XIX, se desarrollo una notación precisa para definir sentencias sobre todo tipo de elementos del mundo y especificar relaciones entre ellos (compárese esto con la notación aritmética). Ya en 1965 existían programas que, en principio, resolvían cualquier problema resoluble descrito en notación lógica. La llamada tradición logista dentro del campo de la inteligencia artificial trata de construir sistemas inteligentes a partir de estos programas. Este enfoque presenta dos obstáculos:\n",
    "- No es fácil transformar conocimiento informal y expresarlo en los términos formales que requieren de notación lógica.\n",
    "- Hay una gran diferencia entre poder resolver un problema «en principio» y hacerlo en la práctica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Agentes inteligentes <a class=\"anchor\" id=\"t1_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un **agente** es cualquier entidad autónoma (software, hardware o ambas) capaz de percibir su entorno con la ayuda de **sensores** y actuar en ese entorno utilizando **actuadores**. El termino **percepción** se utiliza en este contexto para indicar que el agente puede recibir entradas en cualquier instante. La **secuencia de percepciones** de un agente refleja el historial completo de lo que el agente ha recibido.\n",
    "\n",
    "Un **agente racional**:\n",
    "- Hace lo correcto para obtener el mejor resultado.\n",
    "- Necesita definir una medida de rendimiento para obtener el mejor resultado.\n",
    "- Una medida de rendimiento evalua la secuencia de entorno.\n",
    "\n",
    "<center><img src=\"../img/AgenteIA.jpeg\"/></center>\n",
    "\n",
    "\n",
    "La función que describe el comportamiento de un agente se puede presentar en forma de tabla. Suponer un mundo hecho a medida para una aspiradora, que tiene solamente dos localizaciones: cuadrícula A y cuadrícula B. La aspiradora puede:\n",
    "- Percibir en qué cuadrante se encuentra.\n",
    "- Percibir si hay suciedad en el cuadrante. \n",
    "- Puede elegir si se mueve a la derecha, izquierda, aspirar la suciedad o no hacer nada.  \n",
    "\n",
    "Una función muy simple vendría dada por: si la cuadrícula en la que se encuentra está sucia, entonces aspirar, de otra forma, cambiar de cuadrícula.\n",
    "\n",
    "<center><img src=\"../img/AgenteAspirador.jpeg\"/></center>\n",
    "\n",
    "**Propiedades de un agente**\n",
    "- **Autonomía**: Es independiente, se apoya en el entorno.\n",
    "- **Sociabilidad**: Se comunica con otros iguales.\n",
    "- **Reactividad** Reacciona ante eventos.\n",
    "- **Proactividad**: Es capaz de promover acciones. \n",
    "- **Adaptabilidad**: Se pueden desenvolver ante cambios en el entorno sin cambiar el agente. \n",
    "- **Movilidad**: Es capaz de realizar acciones.\n",
    "- **Veracidad**: Si un agente tiene que hacer una acción realizara solo esa acción.\n",
    "- **Racionalidad**: Actúa racionalmente para que lo haga lo mejor posible de acuerdo a unos criterios. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Buen comportamiento: el concepto de racionalidad**\n",
    "\n",
    "“Actuar racionalmente consiste en realizar el conjunto de acciones que lleven a cumplir un objetivo de la mejor manera con el conocimiento que se tiene”. Por tanto, el comportamiento racional no requiere necesariamente de pensamiento (deliberación), y es totalmente independiente de las metas.\n",
    "\n",
    "La Racionalidad implica:\n",
    "- Exploración para recopilar información.\n",
    "- Aprendizaje de lo que percibe.\n",
    "- Autonomia para completar conocimiento parcial.\n",
    "\n",
    "**_Racionalidad_**\n",
    "\n",
    "En el caso del enfoque de la IA según las «leyes del pensamiento», todo el énfasis se pone en hacer inferencias correctas. Una manera racional de actuar es llegar a la conclusión lógica de que si una acción dada permite alcanzar un objetivo. Sin embargo, el efectuar una inferencia correcta no depende siempre de la racionalidad, ya que existen situaciones para las que no hay nada correcto que hacer y en las que hay que tomar una decisión.\n",
    "\n",
    "¿Qué significa hacer lo correcto? Como primera aproximación se puede decir que lo correcto es aquello que permite al agente obtener el mejor resultado posible.\n",
    "\n",
    "La racionalidad en un instante dado depende de cuatro factores:\n",
    "- La medida de rendimiento que define el criterio de exito.\n",
    "- El conocimiento del medio que tiene el agente.\n",
    "- Las acciones que el agente puede realizar.\n",
    "- La secuencia de percepciones recibida.\n",
    "\n",
    "Obtener una racionalidad perfecta (hacer siempre lo correcto) no es posible en entornos complejos. La demanda computacional que esto implica es demasiado grande. Se adoptará la hipótesis de trabajo de que la racionalidad perfecta es un buen punto de partida para el análisis. Lo cual simplifica el problema y proporciona el escenario base adecuado. Cuando no se cuenta con el tiempo suficiente para efectuar todos los cálculos deseables **_la racionalidad limitada_** nos permite actuar adecuadamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Entorno de trabajo_**\n",
    "\n",
    "Para diseñar un agente Racional el primer paso debe ser siempre especificar un Entorno de Trabajo de la forma más completa posible: REAS (Rendimiento, Entorno, Actuadores, Sensores).\n",
    "\n",
    "- **Rendimiento**. Cualidades deseables que el agente debería tener. Seguro, rápido, legal, viaje confortable, maximiza el beneficio.\n",
    "- **Entorno**. ¿Dónde se va a desenvolver nuestro agente? Carreteras, tráfico, peatones, clientes, tiempo (clima).\n",
    "- **Actuadores**. Elementos que nos permitan modificar ese entorno. Dirección, acelerador, freno, señal, bocina, visualizador...\n",
    "- **Sensores**. Permiten conocer la situación instantánea del entorno. Cámaras, sónar, GPS, tacómetro, acelerómetro, sensores del motor. \n",
    "\n",
    "**Propiedades de los entornos de trabajo**\n",
    "- **Totalmente observable vs. parcialmente observable**: Un entorno de trabajo es, efectivamente, totalmente observable si los sensores detectan todos los aspectos que son relevantes en la toma de decisiones.\n",
    "- **Determinista vs. estocástico**: Si el siguiente estado del medio está totalmente determinado por el estado actual y la acción ejecutada por el agente, entonces se dice que el entorno es determinista.\n",
    "- **Episódico vs. secuencial**: En un entorno de trabajo episódico, la experiencia del agente se divide en episodios atómicos, cada episodio consiste en la percepción del agente y la realización de una única acción posterior, donde cada elección de la acción en cada episodio depende sólo del episodio en sí mismo. En entornos secuenciales, por otro lado, la decisión presente puede afectar a decisiones futuras.\n",
    "- **Estático vs. dinámico**: En los nedios estáticos el agnete no necesita estar pendiente del mundo mientras está tomando una decisión, ni necesita preocuparse sobre el paso del tiempo. Los medios dinámicos, por el contrario, están preguntando continuamente al agente qué quiere hacer. Si el entorno no cambia con el paso del tiempo, pero el rendimiento del agente cambia, entonces se dice que el medio es semidinámico.\n",
    "- **Discreto vs. continuo**: La distinción entre discreto y continuo se puede aplicar al estado del medio, a la forma en la que se maneja el tiempo y a las percepciones y acciones del agente.\n",
    "- **Agente individual vs. multiagente**: La distinción entre el entorno de un agente individual y el de un sistema multiagente puede parecer suficientemente simple. Por ejemplo, un agente resolviendo un crucigrama por sí mismo está claramente en un entorno de agente individual, mientras que un agente que juega al ajedrez está en un entorno con dos agentes.\n",
    "\n",
    "La siguiente ficura presenta las propiedades de un número de entornos:\n",
    "\n",
    "<center><img src=\"../img/EntornosDeTrabajo.jpeg\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tipos de agentes**\n",
    "\n",
    "_¿Cómo trabaja internamente un agente?_\n",
    "\n",
    "El trabajo de la IA es diseñar el **programa del agente** que implemente la función del agente que proyecta las percepciones en las acciones. Se asume que este programa se ejecutará en algún tipo de computador con sensores físicos y actuadores, lo cual se conoce como **arquitectura**: \n",
    "\n",
    "**_Agente = arquitectura + programa_**\n",
    "\n",
    "Los programas de los agentes reciben las percepciones actuales como entradas de los sensores y devuelven una acción a los actuadores. Hay que tener en cuenta la diferencia entre los programas de los agentes, que toman la percepción actual como entrada, y la función del agente, que recibe la percepción histórica completa.\n",
    "\n",
    "Tipos básicos de programas para agentes que encarnan los principios que subyacen en casi todos los sistemas inteligentes:\n",
    "\n",
    "**_- Agentes reactivos simples._**\n",
    "El tipo de agente más sencillo es el agente reactivo simple. Estos agentes seleccionan las acciones sobre la base de las percepciones actuales, ignorando el resto de las percepciones históricas. \n",
    "\n",
    "**_- Agentes reactivos basados en modelos._**\n",
    "Un agente reactivo simple con estado interno, muestra cómo la percepción actual se combina con el estado interno antiguo para generar la descripción actualizada del estado actual. Además de interpretar la nueva percepción a partir del conocimiento existente sobre el estado, utiliza información relativa a la forma en la que evoluciona el mundo.\n",
    "La actualización del estado según pasa el tiempo requiere codificar dos tipos de conocimiento en el programa del agente.\n",
    "- Primero, se necesita alguna información acerca de cómo evoluciona el mundo independientemente del agente.\n",
    "- Segundo, se necesita más información sobre cómo afectan al mundo las acciones del agente.\n",
    "\n",
    "**_- Agentes basados en objetivos._** \n",
    "Es unn agente basado en objetivos y basado en modelos, que almacena información del estado del mundo, así como del conjunto de objetivos que intenta alcanzar, y que es capaz de seleccionar la acción que eventualmente lo guiará hacia la consecución de sus objetivos.\n",
    "\n",
    "**_- Agentes basados en utilidad._** \n",
    "Es un agente basado en utilidad y basado en modelos utiliza un modelo del mundo, junto con una función de utilidad que calcula sus preferencias entre los estados del mundo.\n",
    "- Primero, cuando haya objetivos conflictivos, y sólo se puedan alcanzar algunos de ellos.\n",
    "- Segundo, cuando haya varios objetivos por los que se pueda guiar el agente, y ninguno de ellos se pueda alcanzar con certeza.\n",
    "\n",
    "**_- Agentes que aprenden._** \n",
    "Un agente que aprende se puede dividir en cuatro componentes conceptuales. La distinción más entre el **elemento de aprendizaje** y el **elemento de actuación** es que el primero está responsabilizado de hacer mejoras y el segundo se responsabiliza de la selección de acciones externas. \n",
    "\n",
    "El elemento de aprendizaje se realimenta con las críticas sobre la actuación del agente y determina cómo se debe modificar el elemento de actuación para proporcionar mejores resultados en el futuro.\n",
    "\n",
    "La crítica indica al elemento de aprendizaje qué tal lo está haciendo el agente con respecto a un nivel de actuación fijo,  la percepción por sí misma no lo indica.\n",
    "\n",
    "El generador de problemas es responsable de sugerir acciones que lo guiarán hacia experiencias nuevas e informativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Resolver problemas mediante búsqueda<a class=\"anchor\" id=\"t2\"></a>\n",
    "![title](../img/Divider.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se describe una clase de **agente basado en objetivos** llamado agente **resolvente-problemas**, que deciden qué hacer para encontrar secuencias de acciones que conduzcan a los estados deseables. Se describe con precisión los elementos que constituyen el **problema** y su **solución**. Posteriormente, se describen los algoritmos de propósito general que podamos utilizar para resolver estos problemas y así comparar las ventajas de cada algoritmo. \n",
    "\n",
    "Los problemas de búsqueda implican un agente al que se le da un _estado inicial_ y un _estado objetivo_, y que devuelve una solución de cómo llegar del primero al segundo. Una aplicación de navegación utiliza un proceso de búsqueda típico, en el que el agente (la parte pensante del programa) recibe como datos de entrada tu ubicación actual y tu destino deseado y, basándose en un algoritmo de búsqueda, devuelve un camino sugerido. Sin embargo, hay muchas otras formas de problemas de búsqueda, como rompecabezas o laberintos.\n",
    "\n",
    "Para encontrar la solución a un 15 rompecabezas habría que utilizar un algoritmo de búsqueda.\n",
    "\n",
    "<center><img src=\"../img/SearchPuzzle.jpeg\"/></center>\n",
    "\n",
    "- **Agente**: Entidad que percibe su entorno y actúa sobre él. En una aplicación de navegación, por ejemplo, el agente sería la representación de un coche que debe decidir qué acciones realizar para llegar a su destino.\n",
    "- **Estado**: Configuración de un agente en su entorno. Por ejemplo, en un puzzle del 15, un estado es cualquier forma en la que todos los números están dispuestos en el tablero.\n",
    "- **Acciones**: Opciones que se pueden tomar en un estado. Más concretamente, al recibir el estado s como entrada, Actions(s) devuelve como salida el conjunto de acciones que se pueden ejecutar en el estado s.\n",
    "\n",
    "Un problema puede definirse formalmente por cinco componentes: \n",
    "- **Estado inicial**: Estado del que parte el algoritmo de búsqueda. En una aplicación de navegación, sería la ubicación actual.\n",
    "- **Función sucesor**: Una descripción de qué estado resulta de realizar cualquier acción aplicable en cualquier estado. Más concretamente, al recibir el estado s y la acción a como entrada, Results(s, a) devuelve el estado resultante de realizar la acción a en el estado s.\n",
    "- **Estados o espacio de estados**: Conjunto de todos los estados alcanzables desde el estado inicial mediante cualquier secuencia de acciones. El espacio de estados puede visualizarse como un grafo dirigido con estados, representados como nodos, y acciones, representadas como flechas entre nodos.\n",
    "\n",
    "<center><img src=\"../img/SearchPuzzle2.jpeg\"/></center>\n",
    "\n",
    "- **Función objetivo**: Condición que determina si un estado dado es un estado objetivo.\n",
    "- **Coste del camino**: Coste numérico asociado a una ruta determinada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resolución de problemas de búsqueda**\n",
    "\n",
    "- **Solución**: Secuencia de acciones que dirigen el sistema desde un estado inicial a un estado que verifique la prueba objetivo.\n",
    "- **Solución óptima**: Solución que tiene el menor coste de camino entre todas las soluciones.\n",
    "\n",
    "> Nota: No confundir unicidad de la solución con solución óptima. La solución óptima es aquella que tiene el costo más pequeño, pero puede haber muchas más soluciones que tengan el mismo costo. \n",
    "\n",
    "\n",
    "**_Búsqueda de soluciones_**\n",
    "\n",
    "Esto se hace mediante búsqueda a través del espacio de estados. Nos centraremos en búsquedas que utilizan un **árbol de búsqueda** explícito generado por el estado inicial (nodo) y la función sucesor, definiendo así el espacio de estados. En general, podemos tener un **grafo de búsqueda** más que un árbol, cuando el mismo estado puede alcanzarse desde varios caminos.\n",
    "\n",
    "En un proceso de búsqueda, los datos suelen almacenarse en los nodos de un árbol o grafo de búsqueda, una estructura de datos, donde cada nodo contiene los siguientes datos:\n",
    "- Un estado.\n",
    "- Su nodo padre, a través del cual se generó el nodo actual.\n",
    "- La acción que se aplicó al estado del padre para llegar al nodo actual.\n",
    "- El coste del camino desde el estado inicial hasta este nodo.\n",
    "\n",
    "Los nodos contienen información que los hace muy útiles para los algoritmos de búsqueda. Contienen un estado, que se puede comprobar mediante el test objetivo para ver si es el estado final. Si lo es, el coste del camino del nodo puede compararse con los costes de los caminos de otros nodos, lo que permite elegir la solución óptima,\n",
    "\n",
    "Sin embargo, los nodos son simplemente una estructura de datos: no buscan, sino que guardan información. Para buscar realmente, utilizamos **estrategia de búsqueda**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Estrategias de búsqueda no informada <a class=\"anchor\" id=\"t2_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las estrategias de **búsqwueda no informada** (llamada también **búsqueda a ciegas**) englobadas cinco estrategias de búsqueda. El término significa que ellas no tienen información adicional acerca de los estados más allá de la que proporciona la definición del problema. Todo lo que ellas pueden hacer es generar los sucesores y distinguir entre un estado objetivo de uno que no lo es. Las estrategias que saben si un estado no objetivo es «más prometedor» que otro se llaman **búsqueda informada** o **búsqueda heurística**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Búsqueda en profundidad (Depth-First Search)**\n",
    "\n",
    "Un algoritmo de búsqueda en profundidad agota cada una de las direcciones antes de intentar otra dirección. Siempre expande el nodo más profundo en la frontera actual del árbol de búsqueda. \n",
    "\n",
    "> Frontera: Colección de nodos que se han generado pero todavía no se han expandido.\n",
    "\n",
    "Cuando esos nodos se expanden, son quitados de la frontera, así entonces la búsqueda retrocede al siguiente nodo más superficial que todavía tenga sucesores inexplorados. En estos casos, la frontera se gestiona como una estructura de datos en en pila LIFO (último en entrar primero en salir). \n",
    "\n",
    "<center><img src=\"../img/BProfundidad.jpeg\"/></center>\n",
    "\n",
    "Búsqueda primero en profundidad sobre un árbol binario. Los nodos que se han expandido y no tienen descendientes en la frontera se pueden quitar de la memoria; estos se muestran en negro. Los nodos a profundidad 3 se suponen que no tienen sucesores y M es el nodo objetivo\n",
    "\n",
    "Ventajas:\n",
    "- En el mejor de los casos, este algoritmo es el más rápido. Si \"tiene suerte\" y siempre elige el camino correcto hacia la solución (por casualidad), entonces la búsqueda en profundidad es la que menos tiempo tarda en llegar a la solución.\n",
    "Contras:\n",
    "- Es posible que la solución encontrada no sea óptima.\n",
    "- En el peor de los casos, este algoritmo explorará todos los caminos posibles antes de encontrar la solución, por lo que tardará el mayor tiempo posible en llegar a ella."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Búsqueda en anchura (Breadth-First Search)**\n",
    "\n",
    "La búsqueda en anchura es una estrategia sencilla en la que se expande primero el nodo raíz, a continuación se expanden todos los sucesores del nodo raíz, después sus sucesores, etc.\n",
    "\n",
    "La frontera es una estructura de cola FIFO (Primero en entrar, primero en salir). La cola FIFO pone todos los nuevos sucesores generados al final de la cola, lo que significa que los nodos más superficiales se expanden antes que los nodos más profundos. \n",
    "\n",
    "\n",
    "<center><img src=\"../img/BAnchura.jpeg\"/></center>\n",
    "\n",
    "Búsqueda primero en anchura sobre un árbol binario sencillo. En cada etapa, el próximo nodo a expandir se indica con una marca.\n",
    "\n",
    "Ventajas:\n",
    "- Este algoritmo garantiza encontrar la solución óptima.\n",
    "Desventajas:\n",
    "- Está casi garantizado que este algoritmo tarda más que el tiempo mínimo en ejecutarse.\n",
    "- En el peor de los casos, este algoritmo tarda el mayor tiempo posible en ejecutarse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Búsquedade costo uniforme**\n",
    "\n",
    "En vez de expandir el nodo más superficial, la búsquedade costo uniforme expande el nodo n con el camino de costo más pequeño. Notemos que, si todos los costos son iguales, es idéntico a la búsqueda en anchura. La búsqueda de costo uniforme no se preocupa por el número de pasos que tiene un camino, pero sí sobre su coste total. Podemos garantizar completitud si el costo de cada paso es  mayor o igual a alguna constante positiva pequeña e. Esta condiciónes también suficiente para asegurar optimización. Significa que el costo de un camino siempre aumenta cuando vamos por él. De esta propiedad, es fácil ver que el algoritmo expande nodos que incrementan el coste del camino. Por lo tanto, el primer nodo objetivo seleccionado para la expansión es la solución óptima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Búsqueda en profundidad acotada**\n",
    "\n",
    "Busca aliviar el problema de árboles ilimitados aplicando la búsquedaacotada en profundidad con un límitede profundidad L predeterminado. Es decir, los nodos a profundidad L se trataráncomo si no tuvieran ningúnsucesor. El límitede profundidad resuelve  el problema del camino infinito. Lamentablemente, tambiénintroduce una fuente adicional de incompletitud si escogemos un L < d, es decir, el objetivo está fuera del límite de profundidad.\n",
    "\n",
    "A veces, los límitesde profundidad puedenestar basados en el conocimiento del problema. Este número, conocido como **diámetro del espacio de estados**, nos da un mejor límitede profundidad, que conduce a una búsquedacon profundidad limitada más eficiente. Para la mayor parte de problemas, sin embargo, no conoceremos un límitede profundidad bueno hasta que hayamos resuelto el problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Búsqueda en profundidad iterativa**\n",
    "\n",
    "La búsqueda en profundidad iterativa es una estrategia que encuentra el mejor límite de profundidad. Esto se consigue aumentando gradualmente el límite (primero 0, después 1, después 2, etcétera) hasta que encontramos un objetivo. \n",
    "\n",
    "La búsqueda en profundidad iterativa combina las ventajas de la búsqueda en profundidad simple y la búsqueda en anchura. \n",
    "\n",
    "En la búsqueda en profundidad, sus exigencias de memoria son muy modestas: O(bd). La búsqueda en anchura es completa cuando el factor de ramificación es finito y óptima cuando el coste del camino es una función que no disminuye con la profundidad del nodo. \n",
    "\n",
    "<center><img src=\"../img/BProfundidadIterativa.jpeg\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resumen búsquedas no informadas**\n",
    "\n",
    "<center><img src=\"../img/EstrategiasBusqueda.jpeg\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evitar estados repetidos**\n",
    "\n",
    "Hasta este punto, casi hemos ignorado una de las complicaciones más importantes al proceso de búsqueda: la posibilidad de perder tiempo expandiendo estados que ya han sido visitados y expandidos. \n",
    "\n",
    "Para algunos problemas, esta posibilidad nunca aparece, el espacio de estados es un árbol y hay sólo un camino a cada estado. Para otros es inevitable, esto incluye todos los problemas donde las acciones son reversibles, como son los problemas de búsqueda de rutas y los puzles que deslizan sus piezas. Los árboles de la búsqueda para estos problemas son infinitos.\n",
    "\n",
    "Entonces, si el algoritmo no detecta los estados repetidos, éstos pueden provocar que un problema resoluble llegue a ser irresoluble. La detección por lo general significa la comparación del nodo a expandir con aquellos que han sido ya expandidos; si se encuentra\n",
    "un emparejamiento, entonces el algoritmo ha descubierto dos caminos al mismo estado y puede desechar uno de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Búsqueda con información parcial**\n",
    "\n",
    "Partimos desde un supuesto de que el entorno es totalmente observable y determinista y que el agente conoce cuáles son los efectos de cada acción. Por lo tanto, el agente puede calcular exactamente cuál es el estado resultado de cualquier secuencia de acciones y siempre sabe en qué estado está. Su percepción no proporciona ninguna nueva información después de cada acción. \n",
    "\n",
    "_¿Qué pasa cuando el conocimiento de los estados o acciones es incompleto?_\n",
    "\n",
    "Encontramos que diversos tipos de incompletitud conducen a tres tipos de problemas distintos:\n",
    "- **Problemas sin sensores** (también llamados problemas conformados): Si el agente no tiene ningún sensor, entonces (por lo que sabe) podría estar en uno de los posibles estados iniciales, y cada acción por lo tanto podría conducir a uno de los posibles estados sucesores.\n",
    "- **Problemas de contingencia**: Si el entorno es parcialmente observable o si las acciones son inciertas, entonces las percepciones del agente proporcionan nueva información después de cada acción. Cada percepción posible define una contingencia que debe de planearse. A un problema se le llama entre adversarios si la incertidumbre está causada por las acciones de otro agente.\n",
    "- **Problemas de exploración**: Cuando se desconocen los estados y las acciones del entorno, el agente debe actuar para descubrirlos. Los problemas de exploración pueden verse como un caso extremo de problemas de contingencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Estrategias de búsqueda informada y exploración <a class=\"anchor\" id=\"t2_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las estrategias de búsqueda **no informadas** pueden encontrar soluciones a problemas generando sistemáticamente nuevos estados y evaluando hasta alcanzar un objetivo. \n",
    "\n",
    "Lamentablemente, estas estrategias son increíblemente ineficientes en la mayoría de casos:\n",
    "- No consideran informción sobre estados y objetivos para decidir que camino expandir primero en la frontera.\n",
    "- Son estrategias generales y no consideran características específicas del problema.\n",
    "- Los algoritmos de busqueda no tienen en cuenta el objetivo hasta que están en el nodo objetivo.\n",
    "- En algunos problemas, existe información extra que puede ser usadapara guiar la búsqueda.\n",
    "\n",
    "Una estrategia de **búsqueda informada** puede encontrar soluciones de una manera más eficiente que una estrategia no informada. A la aproximación general se le conoce como **búsqueda primero el mejor**, que es un caso particular del algoritmo general de búsqueda-árboles o de búsqueda-grafos en el cual se selecciona un nodo para la expansión basada en una **función de evaluación**. Se implementa con con una cola con prioridad, expandiendo así siempre el nodo de la frontera que parece ser mejor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Búsqueda voraz primero el mejor**\n",
    "\n",
    "La búsqueda voraz primero el mejor trata de expandir el nodo más cercano al objetivo, alegando que probablemente conduzca rápidamente a una solución. Así, evalúa los nodos utilizando solamente la función heurística f(n) = h(n) en cada nodo, la función estima lo cerca de la meta que está el siguiente nodo. La eficacia del algoritmo depende de la calidad de la función heurística.\n",
    "\n",
    "_Ejemplo:_\n",
    "\n",
    "La siguiente figura muestra el progreso de una búsqueda primero el mejor voraz con hDLR para encontrar un camino desde Arad a Bucarest. El primer nodo a expandir desde Arad será Sibiu, porque está mas cerca de Bucarest que Zerind o Timisoara. El siguiente nodo a expandir será Fagaras, porque es la más cercana. Fagaras en su turno genera Bucarest, que es el objetivo. \n",
    "\n",
    "<center><img src=\"../img/BVoraz.jpeg\"/></center>\n",
    "\n",
    "_Propiedades:_\n",
    "- Completa: No, puede quedarse atascada en bucles. Completa en un espacio finito con comprobación de estados repetidos.\n",
    "- Temporal: O(b^m), pero una buena heurística puede mejorarla mucho.\n",
    "- Espacio: O(b^m), porque mantiene todos los nodos en memoria.\n",
    "- Optima: No."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Búsqueda A\\*: minimizar el costo estimado total de la solución**\n",
    "\n",
    "La búsqueda A*, una evolución del algoritmo de búsqueda del mejor primero, tiene en cuenta lo siguiente: \n",
    "\n",
    ">   f(n) = **g(n) + h(n)** <= C*\n",
    "\n",
    "- h(n): El coste estimado desde la posición actual hasta la meta.\n",
    "- g(n): El coste acumulado hasta la posición actual.\n",
    "- f(n): El coste estimado total del camino que llega al objetivo pasando por n.\n",
    "- C*: El coste de la supuesta solución óptima.\n",
    "\n",
    "Al combinar ambos valores, el algoritmo dispone de una forma más precisa de determinar el coste de la solución y optimizar sus elecciones sobre la marcha. El algoritmo lleva la cuenta de (coste del camino hasta ahora + coste estimado hasta la meta), y una vez que supera el coste estimado de alguna opción anterior, el algoritmo abandona el camino actual y vuelve a la opción anterior, evitando así recorrer un camino largo e ineficiente que h(n) marcó erróneamente como el mejor.\n",
    "\n",
    "_Ejemplo:_\n",
    "\n",
    "<center><img src=\"../img/BusquedaA.jpeg\"/></center>\n",
    "\n",
    "Las heurísticas admisibles son por naturaleza optimistas, porque piensan que el coste de resolver el problema es menor que el que es en realidad. Ya que g(n) es el coste exacto para alcanzar n, tenemos como consecuencia inmediata que la f(n) nunca sobre estima el coste verdadero de una solución a través de n. \n",
    "\n",
    "_Propiedades:_\n",
    "- Completa: Sí, a menos que existan infinitos nodos con f<= f(G).\n",
    "- Temporal: Exponencial.\n",
    "- Espacio: O(b^m), mantiene todos los nodos en memoria.\n",
    "- Optima: Si."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funciones Heurísticas**\n",
    "\n",
    "Una heurística h(n) es consistente si, para cada nodo n y cada sucesor n’ de n generado por cualquier acción a, el coste estimado de alcanzar el objetivo desde n no es mayor que el coste de alcanzar n’ más el coste estimado de alcanzar el objetivo desde n’.\n",
    "\n",
    "> h(n) <= c(n,a,n’) + h(n’)\n",
    "\n",
    "Es decir,h(n) es menor o igual que el coste de cualquier camino desde n hasta el objetivo. Una heurística admisible nunca sobrestima el coste real de alcanzar una solución.\n",
    "\n",
    "_Heurística admisible_\n",
    "\n",
    "<center><img src=\"../img/HeuristicaAdmisible.jpeg\"/></center>\n",
    "\n",
    "- Si h2(n) ≥ h1(n) para todos los n (ambas admisibles) entonces h2 domina a h1.  En este caso, h2 es mejor para la búsqueda.\n",
    "- Costes de búsqueda típicos (número medio de nodos expandidos).\n",
    "- Dadas dos heurísticas admisibles ha,hb: h(n) = max(ha(n), hb(n))\n",
    "\n",
    "_Problemas relajados_\n",
    "- Un problema con menos restricciones en las acciones se denomina **problema relajado**.\n",
    "- El coste de una solución óptima en un problema relajado es una heurística admisible para el problema original.\n",
    "- **Clave**: El costo de la solución ́optima de un problema relajadono es mayor que el costo de la solución óptima del problema real.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Algoritmos de búsqueda local y problemas de optimización <a class=\"anchor\" id=\"t2_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los algoritmos de búsquedaqua vistos hasta ahora se diseñan para explorar sistemáticamente espacios de búsqueda. Esta forma sistemática se alcana manteniendo uno o más caminos en memoria y registrando que alternativas se han explorado en cada punto o a lo largo del camino y cuáles no.\n",
    "\n",
    "Si no importa el camino al objetivo, podemos considerar una clase diferente de algoritmos, que no se preocupen en absoluto de los caminos. Los algoritmos de **búsqueda local** funcionan con un solo **estado actual** que se va optimizando. En este tipo de problemas, lo que interesa es encontrar el mejor estado (solución) de acuerdo con una función objetivo. En este sentido, el espacio de estados está formado por un conjunto completo de configuraciones que cumplen la función objetivo. \n",
    "\n",
    "Los algoritmos de búsqueda local no son sistemáticos, pero presentan dos ventajas claves:\n",
    "- Usan muy poca memoria.\n",
    "- Pueden encontrar a menudo soluciones razonables en espacios de estados grandes o infinitos para los cuales los algoritmos sistemáticos son inadecuados.\n",
    "\n",
    "Por estas ventajas, los algoritmos de **búsqueda local** son útiles para resolver problemas de **optimización**, en los cuales el objetivo es encontrar el mejor estado según una **función objetivo**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Ascensión de colinas**\n",
    "\n",
    "El algoritmo de ascensión de colinas parte de una solución y busca soluciones vecinas, de forma que coge la mejor solución vecina y la compara con la solución actual. Si la solución vecina es mejor pasa a ser la solución actual, repitiendo el proceso. Si la mejor solución vecina no mejora a la solución actual el proceso para, devolviendo la solución actual. \n",
    "\n",
    "El algoritmo de ascensión de colina es simplemente un bucle que continuamente se mueve en dirección del valor creciente, es decir, cuesta arriba. Termina cuando alcanza un pico en donde ningún vecino tiene un valor más alto. El algoritmo no mantiene un árbol de búsqueda, sino una estructura de datos del nodo actual que sólo necesita el registro del estado y su valor de función objetivo. \n",
    "\n",
    "Lamentablemente, la ascensiónde colinas a menudo se atasca por los siguientes motivos:\n",
    "- Máximo local: Un máximo local es un pico que es más alto que cada uno de sus estados vecinos pero más bajo que el máximo global.\n",
    "- Crestas: Las crestas causan una secuencia de máximos locales que hace muy difícil la navegación para los algoritmos avaros.\n",
    "- Meseta: Una meseta es un área del paisaje del espacio de estados donde la función de evaluación es plana.\n",
    "\n",
    "<center><img src=\"../img/BusquedaLocal.jpeg\"/></center>\n",
    "\n",
    "Para entender esto, consideramos la forma o el paisaje del espacio de estados, que tiene «posición» (definido por el estado) y «elevación» (definido por el valor de la función de coste heurística o función objetivo). Si la elevación corresponde al costo, entonces el objetivo es encontrar el valle más bajo (un mínimo global); si la elevación corresponde a una función objetivo, entonces el objetivo es encontrar el pico más alto (un máximo global)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Búsqueda por haz local**\n",
    "\n",
    "Guardar solamente un nodo en la memoria podría parecer una reacción extrema para el problema de limitaciones de memoria. El algoritmo de búsqueda por haz local guarda la pista de k estados (no sólo uno). Comienza por k estados (soluciones) generados aleatoriamente. \n",
    "\n",
    "En cada iteración se generan todos los estados sucesores de los k estado. Si alguno es un objetivo, entonces para. Si no, elige los mejores k sucesores de la lista completa de sucesores y repite el ciclo. \n",
    "\n",
    "El problema es que los k mejores sucesores tienen a estar en la misma zona. Como solución, se pueden elegir aleatoriamente los k mejores sucesores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Algoritmos Genéticos**\n",
    "\n",
    "Un algoritmo genético es una variante de la búsqueda de haz en la que los estados sucesores se generan combinando dos estados padres.\n",
    "\n",
    "Como en la búsqueda de haz, los algoritmos genéticos comienzan con un conjunto de k estados generados aleatoriamente, llamados población. Cada estado, o individuo, está representado como una cadena sobre un alfabeto finito (normalmente cadenas de 1s o 0s).\n",
    "\n",
    "Cada estado está tasado con una función idoneidad, la cual debería devolver valores más altos para estados mejores.\n",
    "\n",
    "En (c) se seleccionan dos pares, de manera aleatoria, para la reproducción, de acuerdo con las probabilidades en (b).  Notemos que un individuo se selecciona dos veces y uno ninguna. Para que cada par se aparee, se elige aleatoriamente un punto de cruce de las posiciones en la cadena. \n",
    "\n",
    "En (d) los descendientes se crean cruzando las cadenas paternales en el punto de cruce. Por ejemplo, el primer hijo del primer par consigue los tres primeros dígitos del primer padre y los dígitos restantes del segundo padre. \n",
    "\n",
    "<center><img src=\"../img/BAlgoGeneticos.jpeg\"/></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
